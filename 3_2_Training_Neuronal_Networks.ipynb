{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "106a64ac669f4e029179fc7bc126eabf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b892945981841f78984ce1dff5f081c",
              "IPY_MODEL_8368c2607e3846d59de310e96beb6658",
              "IPY_MODEL_6d61ac8c070e492a9a1caccf3959687d"
            ],
            "layout": "IPY_MODEL_593e884f17844f77a6f486112c27d2d3"
          }
        },
        "2b892945981841f78984ce1dff5f081c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90606a47e4064bd8b41e0174d7ae1942",
            "placeholder": "​",
            "style": "IPY_MODEL_fc1ffca47f074a1593b166daa01e3e77",
            "value": "100%"
          }
        },
        "8368c2607e3846d59de310e96beb6658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d58e4dc02b294ac49693e52005a74dbc",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bbe79f78a8d458b9c5eaa75464c71fd",
            "value": 170498071
          }
        },
        "6d61ac8c070e492a9a1caccf3959687d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3964626412d94923880aba23be029b97",
            "placeholder": "​",
            "style": "IPY_MODEL_98976b8d1cf148caad92917d424dda2f",
            "value": " 170498071/170498071 [00:13&lt;00:00, 13651029.86it/s]"
          }
        },
        "593e884f17844f77a6f486112c27d2d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90606a47e4064bd8b41e0174d7ae1942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc1ffca47f074a1593b166daa01e3e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d58e4dc02b294ac49693e52005a74dbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bbe79f78a8d458b9c5eaa75464c71fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3964626412d94923880aba23be029b97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98976b8d1cf148caad92917d424dda2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mK5XAIf9jga"
      },
      "source": [
        "#Training Neural Networks\n",
        "In this lab session, we will practice the training techniques and recipes seen during the theoretical sessions. Remember that there are three main aspects you have to consider:\n",
        "\n",
        "\n",
        "1.   One time setup considerations.\n",
        "2.   Improve your training error.\n",
        "3.   Improve your test error.\n",
        "\n",
        "We will stick ourselves to a fixed MLP architecture and see how different training techniques impact our results, both in train and development. Finally, using all the lessons learned, we will train our MLP and check the results in the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRhTJGkRAcFt"
      },
      "source": [
        "##The dataset\n",
        "We will work with a dataset of images called [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html). In this dataset, we have images of size $32 \\times 32 \\times 3$, corresponding to height (H), width (W) and channels (C). Remember that coloured images use 3 channels (red-green-blue).\n",
        "\n",
        "All the images of the dataset are classified into 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship and truck. So, our task is to build a neural network that classifies images correctly. But first of all, let's download the dataset to prepare it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLW8N0ib6KI4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "106a64ac669f4e029179fc7bc126eabf",
            "2b892945981841f78984ce1dff5f081c",
            "8368c2607e3846d59de310e96beb6658",
            "6d61ac8c070e492a9a1caccf3959687d",
            "593e884f17844f77a6f486112c27d2d3",
            "90606a47e4064bd8b41e0174d7ae1942",
            "fc1ffca47f074a1593b166daa01e3e77",
            "d58e4dc02b294ac49693e52005a74dbc",
            "3bbe79f78a8d458b9c5eaa75464c71fd",
            "3964626412d94923880aba23be029b97",
            "98976b8d1cf148caad92917d424dda2f"
          ]
        },
        "outputId": "74b45d35-580e-4713-824f-1a293d1acc0a"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, Subset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "training_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n",
        "\n",
        "print(f'Dataset samples: {len(training_data)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "106a64ac669f4e029179fc7bc126eabf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Dataset samples: 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlAxm5BJCPMc"
      },
      "source": [
        "We have only downloaded training images, to have a dataset of 50 thousand images. Remember that test images cannot be used during the design and development of our neural network. However, to guide our decisions regarding hyperparameters, we will generate a **development set**. The best way to do that is to use a **stratified** partition, i.e. a random partition where we maintain the original distribution of classes. For that purpose, we use the `train_test_split()` function of scikit-learn. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iz9gMmeG-MO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c05e06f-7e4c-4ab8-84a4-1a7f7038e4f8"
      },
      "source": [
        "# Split the indices in a stratified way\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "indices = np.arange(len(training_data))\n",
        "train_indices, dev_indices = train_test_split(indices, train_size=40000, stratify=training_data.targets, random_state=42)\n",
        "\n",
        "train_set = Subset(training_data, train_indices)\n",
        "dev_set = Subset(training_data, dev_indices)\n",
        "\n",
        "print(f'Train samples: {len(train_set)}')\n",
        "print(f'Dev samples: {len(dev_set)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 40000\n",
            "Dev samples: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8C6-qJqFrx0"
      },
      "source": [
        "Check whether both sets are balanced in terms of the number of samples for each class. The following cell calculates the percentage of samples of each set for each of the labels. Remember that train and dev sets should follow the same distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoxXLtgfO2ZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c457bd6e-c6f6-4e05-9109-b16389522d4c"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "train_counter = Counter(list(zip(*train_set))[1])\n",
        "train_sorted = sorted(train_counter.items(), key = lambda kv: kv[0])\n",
        "train_sorted_labels = list(zip(*train_sorted))[0]\n",
        "train_percentages = np.array(list(zip(*train_sorted))[1]) / len(train_set)\n",
        "\n",
        "dev_counter = Counter(list(zip(*dev_set))[1])\n",
        "dev_sorted = sorted(dev_counter.items(), key = lambda kv: kv[0])\n",
        "dev_sorted_labels = list(zip(*dev_sorted))[0]\n",
        "dev_percentages = np.array(list(zip(*dev_sorted))[1]) / len(dev_set)\n",
        "\n",
        "print(f\"Train (label, %): {list(zip(train_sorted_labels, train_percentages))}\")\n",
        "print(f\"Dev (label, %): {list(zip(dev_sorted_labels, dev_percentages))}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train (label, %): [(0, 0.1), (1, 0.1), (2, 0.1), (3, 0.1), (4, 0.1), (5, 0.1), (6, 0.1), (7, 0.1), (8, 0.1), (9, 0.1)]\n",
            "Dev (label, %): [(0, 0.1), (1, 0.1), (2, 0.1), (3, 0.1), (4, 0.1), (5, 0.1), (6, 0.1), (7, 0.1), (8, 0.1), (9, 0.1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqlMtnJ41YQL"
      },
      "source": [
        "As can be seen, both sets are perfectly balanced: each class represents the 10% of both sets. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ6CCkHJBOhC"
      },
      "source": [
        "We can have a look at the images of the train set, to have an idea of what kind of problem we are facing.\n",
        "\n",
        "**NOTE:** When using images in Pytorch, the tensors are arranged as (C, H, W), instead of the more common (H, W, C) format. Take that into account, specially for visualization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tN6ctN-D7PJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "cbd7ee92-dcb0-44d5-8024-fddc8409655e"
      },
      "source": [
        "labels_map = {\n",
        "    0: \"airplane\",\n",
        "    1: \"automobile\",\n",
        "    2: \"bird\",\n",
        "    3: \"cat\",\n",
        "    4: \"deer\",\n",
        "    5: \"dog\",\n",
        "    6: \"frog\",\n",
        "    7: \"horse\",\n",
        "    8: \"ship\",\n",
        "    9: \"truck\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_set), size=(1,)).item()\n",
        "    img, label = train_set[sample_idx]    \n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.permute(1, 2, 0)) # Permute since Pytorch uses (C, H, W) and plt needs (H, W, C)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcrwzkREKdyK"
      },
      "source": [
        "##The neural network\n",
        "We will use a multi-layer perceptron (MLP) for this task. As we said before, we will not change the architecture of the model, as we are not interested on architectural decisions for now (how many layers? How many neurons in each layer?).\n",
        "\n",
        "**EXERCISE:** Design a multi-layer perceptron (MLP) with the following architecture: INPUT -> LINEAR(512) -> ReLU -> LINEAR(512) -> ReLU -> LINEAR(10)\n",
        "\n",
        "**NOTE:** Remember that images are tensors of shape (3, 32, 32) and the input for a linear layer should be a vector (in this case of size $3\\times 32 \\times 32 = 3072$).\n",
        "\n",
        "**TODO:** Decide where and how to explain the issue about the absence of an activation function in the output layer and the Pytorch CrossEntropyLoss (softmax + NLL loss)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElPIT-AnqWiM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5cb3946-55db-46f0-c957-a02679d2c214"
      },
      "source": [
        "# For reproducibility\n",
        "torch.manual_seed(0)\n",
        "\n",
        "class MyMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(MyMLP, self).__init__()\n",
        "      self.flatten = nn.Flatten()\n",
        "      self.linear1 = nn.Linear(3072, 512)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.linear2 = nn.Linear(512, 512)\n",
        "      self.linear3 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.flatten(x)\n",
        "      logits = self.linear1(x)\n",
        "      logits = self.relu(logits)\n",
        "      logits = self.linear2(logits)\n",
        "      logits = self.relu(logits)\n",
        "      logits = self.linear3(logits)\n",
        "\n",
        "      return logits\n",
        "\n",
        "model = MyMLP()\n",
        "\n",
        "# Print the number of trainable parameters\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1841162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O5SA17qBfvD"
      },
      "source": [
        "Your MLP should have 1,841,162 learnable parameters, i.e. slightly above 1.8M parameters. \n",
        "\n",
        "During the set-up of a neural network, many training processes have to be performed, so training time becomes an essential part of the problem. To speed-up our training processes, we will use a GPU availabe in Colab. The following cell assigns `cuda` to the variable `device` if a GPU is available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Zb7wuFkrl_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03d4dc2a-f9ea-432c-ceb8-6d7f69bf2f14"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))\n",
        "model = model.to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "MyMLP(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear1): Linear(in_features=3072, out_features=512, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (linear3): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg7g2Y6cBj-_"
      },
      "source": [
        "We will also define the base train and test functions to use through the lab. Here you have the implementation of the functions `train_loop()` and `test_loop()`. Some details to highlight here: \n",
        "\n",
        "1.   Notice how we use `model.train()` and `model.eval()`. This is very important. As model behaviour during training and testing may be different (due to batch normalization and dropout, for example), Pytorch needs to know the \"mode\" in which we are using the model. It is also important as Pytorch does not store the gradients in `eval` mode, making calculations faster. Thus, when training, set `model.train()` and when testing, set `model.eval()`. \n",
        "2.   The function `test_loop` will be used for both development and test data. The process is the same for both datasets. The only thing that changes is the dataset itself. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MDSOm8K93lw"
      },
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer, device):        \n",
        "    model.train()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "      # Compute prediction and loss\n",
        "      pred = model(X)\n",
        "      loss = loss_fn(pred, y)\n",
        "        \n",
        "      # Backpropagation\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Store loss and accuracy\n",
        "      train_loss += loss.item()\n",
        "      train_acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "      if batch % 100 == 0:\n",
        "        loss, current = loss.item(), batch * len(X)\n",
        "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "      \n",
        "    train_loss /= num_batches\n",
        "    train_acc /= size\n",
        "    return train_loss, train_acc\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn, device):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "          X = X.to(device)\n",
        "          y = y.to(device)\n",
        "          pred = model(X)\n",
        "          test_loss += loss_fn(pred, y).item()\n",
        "          test_acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            \n",
        "    test_loss /= num_batches\n",
        "    test_acc /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*test_acc):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss, test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5cqFPci-9xy"
      },
      "source": [
        "##One time setup considerations\n",
        "During the theoretical sessions, we saw that this step is to decide about activation functions, data preprocessing, weight initialization and batch normalization. Given the time constraints we have for the lab, we will not explore different activation functions. ReLU is our choice for all the layers. Similarly, regarding data preprocessing, we wil only scale the pixel values of the images from [0, 255] to [0, 1], and discard futher exploration. But we will skim through weight initialization and batch normalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ddim5r-dSZ_"
      },
      "source": [
        "###Weight initialization\n",
        "When we use `torch.nn.Linear()`, Pytorch uses Xavier initialization by default. Hence, our `MyMLP` model is configured to use that initialization. Let's train it for 10 epochs to see the results we obtain in train.\n",
        "\n",
        "**EXERCISE:** Fill in the gaps following the comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55mSeTJydU_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2694bf1-1365-41b0-9e6b-b056e43db4e0"
      },
      "source": [
        "import time\n",
        "\n",
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# instantiate a MLP object in the model variable\n",
        "model = MyMLP()\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# create train_dataloader\n",
        "train_dataloader = DataLoader(train_set, batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "# instantiate a cross-entropy loss in the loss_fn variable\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# instantiate a SGD optimizer in the optimizer variable\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_losses, train_accuracies  = [], []\n",
        "start = time.time()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss, train_acc = train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
        "    print(f'train loss: {train_loss}, train_acc: {train_acc}')\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)    \n",
        "end = time.time()\n",
        "print(\"Done!\")\n",
        "print(f'Training time: {end-start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.321399  [    0/40000]\n",
            "loss: 2.298675  [ 6400/40000]\n",
            "loss: 2.301313  [12800/40000]\n",
            "loss: 2.291584  [19200/40000]\n",
            "loss: 2.285453  [25600/40000]\n",
            "loss: 2.281800  [32000/40000]\n",
            "loss: 2.256744  [38400/40000]\n",
            "train loss: 2.289400284957886, train_acc: 0.123825\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.277507  [    0/40000]\n",
            "loss: 2.264313  [ 6400/40000]\n",
            "loss: 2.270339  [12800/40000]\n",
            "loss: 2.260579  [19200/40000]\n",
            "loss: 2.257062  [25600/40000]\n",
            "loss: 2.260245  [32000/40000]\n",
            "loss: 2.251670  [38400/40000]\n",
            "train loss: 2.2621935131072997, train_acc: 0.15635\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.237804  [    0/40000]\n",
            "loss: 2.255041  [ 6400/40000]\n",
            "loss: 2.249975  [12800/40000]\n",
            "loss: 2.224666  [19200/40000]\n",
            "loss: 2.217215  [25600/40000]\n",
            "loss: 2.178922  [32000/40000]\n",
            "loss: 2.193448  [38400/40000]\n",
            "train loss: 2.2293982357025146, train_acc: 0.204175\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.155501  [    0/40000]\n",
            "loss: 2.196642  [ 6400/40000]\n",
            "loss: 2.192002  [12800/40000]\n",
            "loss: 2.162945  [19200/40000]\n",
            "loss: 2.203750  [25600/40000]\n",
            "loss: 2.185112  [32000/40000]\n",
            "loss: 2.134984  [38400/40000]\n",
            "train loss: 2.1876717693328858, train_acc: 0.230775\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 2.143427  [    0/40000]\n",
            "loss: 2.129568  [ 6400/40000]\n",
            "loss: 2.166054  [12800/40000]\n",
            "loss: 2.112760  [19200/40000]\n",
            "loss: 2.163131  [25600/40000]\n",
            "loss: 2.144737  [32000/40000]\n",
            "loss: 2.212461  [38400/40000]\n",
            "train loss: 2.1421538734436036, train_acc: 0.24845\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 2.135482  [    0/40000]\n",
            "loss: 2.125205  [ 6400/40000]\n",
            "loss: 2.115561  [12800/40000]\n",
            "loss: 2.109330  [19200/40000]\n",
            "loss: 2.067723  [25600/40000]\n",
            "loss: 2.052858  [32000/40000]\n",
            "loss: 2.075198  [38400/40000]\n",
            "train loss: 2.101085787200928, train_acc: 0.2598\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 2.003238  [    0/40000]\n",
            "loss: 2.038883  [ 6400/40000]\n",
            "loss: 2.024649  [12800/40000]\n",
            "loss: 2.108525  [19200/40000]\n",
            "loss: 2.049702  [25600/40000]\n",
            "loss: 2.107215  [32000/40000]\n",
            "loss: 2.098220  [38400/40000]\n",
            "train loss: 2.0673800312042236, train_acc: 0.273\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 2.067147  [    0/40000]\n",
            "loss: 2.081777  [ 6400/40000]\n",
            "loss: 2.088174  [12800/40000]\n",
            "loss: 2.038637  [19200/40000]\n",
            "loss: 2.065353  [25600/40000]\n",
            "loss: 1.983237  [32000/40000]\n",
            "loss: 2.004593  [38400/40000]\n",
            "train loss: 2.0390077089309693, train_acc: 0.280675\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.880912  [    0/40000]\n",
            "loss: 2.083016  [ 6400/40000]\n",
            "loss: 1.969815  [12800/40000]\n",
            "loss: 2.132741  [19200/40000]\n",
            "loss: 2.027336  [25600/40000]\n",
            "loss: 1.984849  [32000/40000]\n",
            "loss: 1.981171  [38400/40000]\n",
            "train loss: 2.014312187767029, train_acc: 0.292775\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.959696  [    0/40000]\n",
            "loss: 2.077300  [ 6400/40000]\n",
            "loss: 2.100924  [12800/40000]\n",
            "loss: 2.035835  [19200/40000]\n",
            "loss: 2.084971  [25600/40000]\n",
            "loss: 1.971955  [32000/40000]\n",
            "loss: 2.028795  [38400/40000]\n",
            "train loss: 1.99209054813385, train_acc: 0.2992\n",
            "Done!\n",
            "Training time: 55.95779466629028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6jy6Y6rVi3C"
      },
      "source": [
        "Our training accuracy is 0.299, very close to 0.3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2SovdlgeJ7M"
      },
      "source": [
        "We know from our theoretical sessions that when using ReLU activation function, He or Kaiming initialization should work better. Let's test it. We will implement a new class called `MyMLPKaiming` to apply He initialization to its linear layers. But we will keep the initial MLP architecture unchanged.\n",
        "\n",
        "**EXERCISE:** use `torch.nn.init.kaiming_uniform_` to re-initialize the weights of the linear layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u-zJ_I9dUvN"
      },
      "source": [
        "class MyMLPKaiming(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(MyMLPKaiming, self).__init__()\n",
        "      self.flatten = nn.Flatten()\n",
        "      self.linear1 = nn.Linear(3*32*32, 512)\n",
        "      nn.init.kaiming_uniform_(self.linear1.weight, mode='fan_in', nonlinearity='relu')\n",
        "\n",
        "      self.linear2 = nn.Linear(512, 512)\n",
        "      nn.init.kaiming_uniform_(self.linear2.weight, mode='fan_in', nonlinearity='relu')\n",
        "\n",
        "      self.linear3 = nn.Linear(512, 10)\n",
        "      nn.init.kaiming_uniform_(self.linear3.weight, mode='fan_in', nonlinearity='relu')\n",
        "\n",
        "      self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.flatten(x)\n",
        "      logits = self.linear1(x)\n",
        "      logits = self.relu(logits)\n",
        "      logits = self.linear2(logits)\n",
        "      logits = self.relu(logits)\n",
        "      logits = self.linear3(logits)\n",
        "\n",
        "      return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su92aJHJq8td"
      },
      "source": [
        "We will train the new model just as before, to compare the results fairly.\n",
        "\n",
        "**EXERCISE:** Fill in the gaps following the comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az6H9xRNed0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e379789-166a-4c32-cbaa-5fee6930f9e5"
      },
      "source": [
        "import time\n",
        "\n",
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# instantiate a MLPKaiming object in the model variable\n",
        "model = MyMLPKaiming()\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# create train_dataloader\n",
        "train_dataloader = DataLoader(train_set, batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "# instantiate a cross-entropy loss in the loss_fn variable\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# instantiate a SGD optimizer in the optimizer variable\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_losses, train_accuracies  = [], []\n",
        "start = time.time()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss, train_acc = train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
        "    print(f'train loss: {train_loss}, train_acc: {train_acc}')\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)    \n",
        "end = time.time()\n",
        "print(\"Done!\")\n",
        "print(f'Training time: {end-start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.576493  [    0/40000]\n",
            "loss: 2.255191  [ 6400/40000]\n",
            "loss: 2.205885  [12800/40000]\n",
            "loss: 2.031555  [19200/40000]\n",
            "loss: 2.023610  [25600/40000]\n",
            "loss: 1.996216  [32000/40000]\n",
            "loss: 2.081941  [38400/40000]\n",
            "train loss: 2.1373119636535645, train_acc: 0.233575\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.011819  [    0/40000]\n",
            "loss: 1.993810  [ 6400/40000]\n",
            "loss: 1.874771  [12800/40000]\n",
            "loss: 2.086034  [19200/40000]\n",
            "loss: 1.822790  [25600/40000]\n",
            "loss: 1.978346  [32000/40000]\n",
            "loss: 1.960433  [38400/40000]\n",
            "train loss: 1.9692356962203978, train_acc: 0.311925\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.000031  [    0/40000]\n",
            "loss: 1.899098  [ 6400/40000]\n",
            "loss: 2.051569  [12800/40000]\n",
            "loss: 1.907200  [19200/40000]\n",
            "loss: 1.868016  [25600/40000]\n",
            "loss: 1.974382  [32000/40000]\n",
            "loss: 2.028292  [38400/40000]\n",
            "train loss: 1.897565640449524, train_acc: 0.339\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.971719  [    0/40000]\n",
            "loss: 1.899888  [ 6400/40000]\n",
            "loss: 1.732381  [12800/40000]\n",
            "loss: 1.893157  [19200/40000]\n",
            "loss: 1.965128  [25600/40000]\n",
            "loss: 1.846370  [32000/40000]\n",
            "loss: 1.898222  [38400/40000]\n",
            "train loss: 1.8532823190689087, train_acc: 0.3544\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.898782  [    0/40000]\n",
            "loss: 1.687359  [ 6400/40000]\n",
            "loss: 1.839790  [12800/40000]\n",
            "loss: 1.720008  [19200/40000]\n",
            "loss: 2.020488  [25600/40000]\n",
            "loss: 1.815910  [32000/40000]\n",
            "loss: 1.892446  [38400/40000]\n",
            "train loss: 1.8214970539093018, train_acc: 0.3673\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.987564  [    0/40000]\n",
            "loss: 1.898907  [ 6400/40000]\n",
            "loss: 1.684171  [12800/40000]\n",
            "loss: 1.965661  [19200/40000]\n",
            "loss: 1.837380  [25600/40000]\n",
            "loss: 1.626323  [32000/40000]\n",
            "loss: 1.700479  [38400/40000]\n",
            "train loss: 1.7971192386627197, train_acc: 0.3751\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.704776  [    0/40000]\n",
            "loss: 1.833216  [ 6400/40000]\n",
            "loss: 1.697687  [12800/40000]\n",
            "loss: 1.689286  [19200/40000]\n",
            "loss: 1.953229  [25600/40000]\n",
            "loss: 1.895254  [32000/40000]\n",
            "loss: 1.735568  [38400/40000]\n",
            "train loss: 1.7766886249542235, train_acc: 0.3828\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.837465  [    0/40000]\n",
            "loss: 1.812254  [ 6400/40000]\n",
            "loss: 1.652487  [12800/40000]\n",
            "loss: 1.635995  [19200/40000]\n",
            "loss: 1.785496  [25600/40000]\n",
            "loss: 1.852312  [32000/40000]\n",
            "loss: 1.585063  [38400/40000]\n",
            "train loss: 1.7586638051986694, train_acc: 0.391075\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.769263  [    0/40000]\n",
            "loss: 1.807620  [ 6400/40000]\n",
            "loss: 1.483950  [12800/40000]\n",
            "loss: 1.569744  [19200/40000]\n",
            "loss: 1.739772  [25600/40000]\n",
            "loss: 1.755484  [32000/40000]\n",
            "loss: 1.759478  [38400/40000]\n",
            "train loss: 1.7425328926086425, train_acc: 0.397025\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.629078  [    0/40000]\n",
            "loss: 1.629498  [ 6400/40000]\n",
            "loss: 1.753302  [12800/40000]\n",
            "loss: 1.635709  [19200/40000]\n",
            "loss: 1.731083  [25600/40000]\n",
            "loss: 1.747033  [32000/40000]\n",
            "loss: 1.889082  [38400/40000]\n",
            "train loss: 1.7280087921142577, train_acc: 0.400525\n",
            "Done!\n",
            "Training time: 54.745646715164185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndoq8dlUfKAE"
      },
      "source": [
        "This is quite a big improvement! When linear layers were initialized with Xavier initialization, we had a training accuracy of 0.29. Now, with He initialization, we achieve 0.40. So far, we have seen that using He initialization our optimization improves faster in 10 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFnx8EtPhl0a"
      },
      "source": [
        "###Batch normalization\n",
        "To implement batch normalization, we have to create another class. We will name it `MyMLPBN`. Remember that batch normalization normalizes activations with learned means and variances on mini-batches. \n",
        "\n",
        "**EXERCISE:** implement the necessary code to apply batch normalization to our MLP, both in the `__init__` and `forward` functions. Create 2 batch normalization layers, as much as hidden layers we have in the network, and apply them correctly in the forward pass."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWmNt1VvhpAo"
      },
      "source": [
        "class MyMLPBN(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(MyMLPBN, self).__init__()\n",
        "      self.flatten = nn.Flatten()\n",
        "      self.linear1 = nn.Linear(3*32*32, 512)\n",
        "      torch.nn.init.kaiming_uniform_(self.linear1.weight)\n",
        "      self.linear1_bn = nn.BatchNorm1d(512)\n",
        "\n",
        "      self.linear2 = nn.Linear(512, 512)\n",
        "      torch.nn.init.kaiming_uniform_(self.linear2.weight)\n",
        "      self.linear2_bn = nn.BatchNorm1d(512)\n",
        "      self.relu = nn.ReLU()\n",
        "\n",
        "      self.linear3 = nn.Linear(512, 10)\n",
        "      torch.nn.init.kaiming_uniform_(self.linear3.weight)      \n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.flatten(x)\n",
        "      logits = self.linear1(x)\n",
        "      logits =  self.linear1_bn(logits)\n",
        "      logits = self.relu(logits)\n",
        "      logits = self.linear2(logits)\n",
        "      logits =  self.linear2_bn(logits)\n",
        "      logits = self.relu(logits)\n",
        "      logits = self.linear3(logits)\n",
        "\n",
        "      return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrs8wG0x1YDf"
      },
      "source": [
        "We are ready to train this new model with batch normalization. Again, we will use the same setting as the previous experiments, to fairly compare the obtained results.\n",
        "\n",
        "**EXERCISE:** fill in the gaps following the comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygVTfYXbip0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f94839-db96-4738-9b64-da180fbb6b97"
      },
      "source": [
        "import time\n",
        "\n",
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# instantiate a MyMLPBN object in the variable model\n",
        "model = MyMLPBN()\n",
        "model = model.to(device)\n",
        "\n",
        "# create train_dataloader\n",
        "train_dataloader = DataLoader(train_set, batch_size, shuffle=True)\n",
        "\n",
        "# instantiate a cross-entropy loss in the loss_fn variable\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# instantiate a SGD optimizer in the optimizer variable\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "train_losses, train_accuracies  = [], []\n",
        "start = time.time()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss, train_acc = train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
        "    print(f'train loss: {train_loss}, train_acc: {train_acc}')\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)    \n",
        "end = time.time()\n",
        "print(\"Done!\")\n",
        "print(f'Training time: {end-start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.817509  [    0/40000]\n",
            "loss: 2.345899  [ 6400/40000]\n",
            "loss: 2.114495  [12800/40000]\n",
            "loss: 1.980695  [19200/40000]\n",
            "loss: 1.765399  [25600/40000]\n",
            "loss: 1.882576  [32000/40000]\n",
            "loss: 1.945652  [38400/40000]\n",
            "train loss: 2.0921828987121582, train_acc: 0.2583\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.961039  [    0/40000]\n",
            "loss: 1.781703  [ 6400/40000]\n",
            "loss: 1.574205  [12800/40000]\n",
            "loss: 2.086886  [19200/40000]\n",
            "loss: 1.637454  [25600/40000]\n",
            "loss: 1.831735  [32000/40000]\n",
            "loss: 1.857150  [38400/40000]\n",
            "train loss: 1.8189907167434693, train_acc: 0.35715\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.951620  [    0/40000]\n",
            "loss: 1.767130  [ 6400/40000]\n",
            "loss: 1.831410  [12800/40000]\n",
            "loss: 1.731973  [19200/40000]\n",
            "loss: 1.642663  [25600/40000]\n",
            "loss: 1.747823  [32000/40000]\n",
            "loss: 1.764001  [38400/40000]\n",
            "train loss: 1.7245716659545898, train_acc: 0.39345\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.812390  [    0/40000]\n",
            "loss: 1.683945  [ 6400/40000]\n",
            "loss: 1.548675  [12800/40000]\n",
            "loss: 1.827245  [19200/40000]\n",
            "loss: 1.747155  [25600/40000]\n",
            "loss: 1.667358  [32000/40000]\n",
            "loss: 1.679645  [38400/40000]\n",
            "train loss: 1.66435025806427, train_acc: 0.4163\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.653943  [    0/40000]\n",
            "loss: 1.352347  [ 6400/40000]\n",
            "loss: 1.644274  [12800/40000]\n",
            "loss: 1.464799  [19200/40000]\n",
            "loss: 1.840215  [25600/40000]\n",
            "loss: 1.693992  [32000/40000]\n",
            "loss: 1.632886  [38400/40000]\n",
            "train loss: 1.6185749670028686, train_acc: 0.432725\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.851068  [    0/40000]\n",
            "loss: 1.737493  [ 6400/40000]\n",
            "loss: 1.336938  [12800/40000]\n",
            "loss: 1.753457  [19200/40000]\n",
            "loss: 1.536329  [25600/40000]\n",
            "loss: 1.451470  [32000/40000]\n",
            "loss: 1.341887  [38400/40000]\n",
            "train loss: 1.5824834987640382, train_acc: 0.446575\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.453067  [    0/40000]\n",
            "loss: 1.726584  [ 6400/40000]\n",
            "loss: 1.547500  [12800/40000]\n",
            "loss: 1.361953  [19200/40000]\n",
            "loss: 1.720446  [25600/40000]\n",
            "loss: 1.692562  [32000/40000]\n",
            "loss: 1.533088  [38400/40000]\n",
            "train loss: 1.553100234222412, train_acc: 0.4563\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.635116  [    0/40000]\n",
            "loss: 1.569665  [ 6400/40000]\n",
            "loss: 1.408708  [12800/40000]\n",
            "loss: 1.508362  [19200/40000]\n",
            "loss: 1.500719  [25600/40000]\n",
            "loss: 1.535597  [32000/40000]\n",
            "loss: 1.339634  [38400/40000]\n",
            "train loss: 1.5259164821624756, train_acc: 0.465575\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.433765  [    0/40000]\n",
            "loss: 1.577800  [ 6400/40000]\n",
            "loss: 1.171863  [12800/40000]\n",
            "loss: 1.342206  [19200/40000]\n",
            "loss: 1.584151  [25600/40000]\n",
            "loss: 1.509007  [32000/40000]\n",
            "loss: 1.613824  [38400/40000]\n",
            "train loss: 1.5038041135787963, train_acc: 0.475825\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.368674  [    0/40000]\n",
            "loss: 1.519955  [ 6400/40000]\n",
            "loss: 1.487127  [12800/40000]\n",
            "loss: 1.324259  [19200/40000]\n",
            "loss: 1.554588  [25600/40000]\n",
            "loss: 1.298149  [32000/40000]\n",
            "loss: 1.552424  [38400/40000]\n",
            "train loss: 1.4796295280456544, train_acc: 0.48305\n",
            "Done!\n",
            "Training time: 56.20701789855957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ihZDtZjjDcK"
      },
      "source": [
        "We got another big boost here! Train accuracy is around 0.48, showing that batch normalization helps a lot in the training process. Notice that batch normalization usually allows increasing the learning rate to speed-up optimization, so let's try it. We will increase the learning rate ten times to check what happens. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4lkG6KK-fZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63944ff2-ab89-42ac-a3ce-6294742bb2b1"
      },
      "source": [
        "import time\n",
        "\n",
        "learning_rate = 1e-2 # New learning rate\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(0)\n",
        "\n",
        "model = MyMLPBN()\n",
        "model = model.to(device)\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_losses, train_accuracies  = [], []\n",
        "start = time.time()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss, train_acc = train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
        "    print(f'train loss: {train_loss}, train_acc: {train_acc}')\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)    \n",
        "end = time.time()\n",
        "print(\"Done!\")\n",
        "print(f'Training time: {end-start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.817509  [    0/40000]\n",
            "loss: 1.871529  [ 6400/40000]\n",
            "loss: 1.615286  [12800/40000]\n",
            "loss: 1.601233  [19200/40000]\n",
            "loss: 1.438730  [25600/40000]\n",
            "loss: 1.508677  [32000/40000]\n",
            "loss: 1.681681  [38400/40000]\n",
            "train loss: 1.7351202632904053, train_acc: 0.386175\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.673471  [    0/40000]\n",
            "loss: 1.472232  [ 6400/40000]\n",
            "loss: 1.237097  [12800/40000]\n",
            "loss: 1.645487  [19200/40000]\n",
            "loss: 1.382110  [25600/40000]\n",
            "loss: 1.435351  [32000/40000]\n",
            "loss: 1.397564  [38400/40000]\n",
            "train loss: 1.4826960027694702, train_acc: 0.48055\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.479679  [    0/40000]\n",
            "loss: 1.390892  [ 6400/40000]\n",
            "loss: 1.483419  [12800/40000]\n",
            "loss: 1.385492  [19200/40000]\n",
            "loss: 1.284133  [25600/40000]\n",
            "loss: 1.385138  [32000/40000]\n",
            "loss: 1.421449  [38400/40000]\n",
            "train loss: 1.374046925354004, train_acc: 0.520675\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.286271  [    0/40000]\n",
            "loss: 1.467597  [ 6400/40000]\n",
            "loss: 1.160307  [12800/40000]\n",
            "loss: 1.351305  [19200/40000]\n",
            "loss: 1.321510  [25600/40000]\n",
            "loss: 1.461307  [32000/40000]\n",
            "loss: 1.378725  [38400/40000]\n",
            "train loss: 1.293421473312378, train_acc: 0.5494\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.230162  [    0/40000]\n",
            "loss: 0.995709  [ 6400/40000]\n",
            "loss: 1.276703  [12800/40000]\n",
            "loss: 1.138074  [19200/40000]\n",
            "loss: 1.309627  [25600/40000]\n",
            "loss: 1.447430  [32000/40000]\n",
            "loss: 1.196785  [38400/40000]\n",
            "train loss: 1.22435755443573, train_acc: 0.579175\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.403505  [    0/40000]\n",
            "loss: 1.189686  [ 6400/40000]\n",
            "loss: 0.834707  [12800/40000]\n",
            "loss: 1.268615  [19200/40000]\n",
            "loss: 1.076646  [25600/40000]\n",
            "loss: 1.012859  [32000/40000]\n",
            "loss: 0.913373  [38400/40000]\n",
            "train loss: 1.1636916016578673, train_acc: 0.59945\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.145747  [    0/40000]\n",
            "loss: 1.285642  [ 6400/40000]\n",
            "loss: 1.187535  [12800/40000]\n",
            "loss: 0.935347  [19200/40000]\n",
            "loss: 1.313569  [25600/40000]\n",
            "loss: 1.408883  [32000/40000]\n",
            "loss: 1.225821  [38400/40000]\n",
            "train loss: 1.1058092641830444, train_acc: 0.6204\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.144987  [    0/40000]\n",
            "loss: 1.079533  [ 6400/40000]\n",
            "loss: 1.019382  [12800/40000]\n",
            "loss: 1.010234  [19200/40000]\n",
            "loss: 1.045371  [25600/40000]\n",
            "loss: 0.945810  [32000/40000]\n",
            "loss: 0.965179  [38400/40000]\n",
            "train loss: 1.050426994037628, train_acc: 0.641\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.895984  [    0/40000]\n",
            "loss: 1.101073  [ 6400/40000]\n",
            "loss: 0.749065  [12800/40000]\n",
            "loss: 0.928708  [19200/40000]\n",
            "loss: 0.979302  [25600/40000]\n",
            "loss: 1.160685  [32000/40000]\n",
            "loss: 1.213116  [38400/40000]\n",
            "train loss: 1.0034986134529114, train_acc: 0.65805\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.858272  [    0/40000]\n",
            "loss: 1.023554  [ 6400/40000]\n",
            "loss: 0.891558  [12800/40000]\n",
            "loss: 1.004827  [19200/40000]\n",
            "loss: 1.011389  [25600/40000]\n",
            "loss: 0.733764  [32000/40000]\n",
            "loss: 0.988856  [38400/40000]\n",
            "train loss: 0.9506250624656677, train_acc: 0.67795\n",
            "Done!\n",
            "Training time: 56.944868087768555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNJBl09O39dS"
      },
      "source": [
        "Just increasing the learning rate to $10^{-2}$, we obtain 0.67 of accuracy in train. As can be seen, the impact of hyperparameters such as learning rate and techniques such as batch normalization can be very significant in the training process of a neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4FfCSz1td3i"
      },
      "source": [
        "##Improve your training error\n",
        "Now that one time setup considerations are clear for us, we will explore optimizers and schedulers to improve our training performance even more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkHuJ_OM6MH0"
      },
      "source": [
        "###SGD with momentum\n",
        "Keeping the same configuration as before, we will test how SGD with momentum works. \n",
        "\n",
        "**EXERCISE:** Substitute the SGD optimizer by SGD with momentum and use a momentum value of 0.9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x4sHG7O6UEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a733050-2b18-4a30-edc0-930fd632b789"
      },
      "source": [
        "import time\n",
        "\n",
        "learning_rate = 1e-2\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(0)\n",
        "\n",
        "model = MyMLPBN()\n",
        "model = model.to(device)\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "train_losses, train_accuracies  = [], []\n",
        "start = time.time()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss, train_acc = train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
        "    print(f'train loss: {train_loss}, train_acc: {train_acc}')\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)    \n",
        "end = time.time()\n",
        "print(\"Done!\")\n",
        "print(f'Training time: {end-start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.817509  [    0/40000]\n",
            "loss: 1.745602  [ 6400/40000]\n",
            "loss: 1.505604  [12800/40000]\n",
            "loss: 1.618249  [19200/40000]\n",
            "loss: 1.452555  [25600/40000]\n",
            "loss: 1.488043  [32000/40000]\n",
            "loss: 1.672304  [38400/40000]\n",
            "train loss: 1.6713283014297486, train_acc: 0.40905\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.594308  [    0/40000]\n",
            "loss: 1.316226  [ 6400/40000]\n",
            "loss: 1.333772  [12800/40000]\n",
            "loss: 1.609985  [19200/40000]\n",
            "loss: 1.293670  [25600/40000]\n",
            "loss: 1.309060  [32000/40000]\n",
            "loss: 1.210826  [38400/40000]\n",
            "train loss: 1.4236928086280822, train_acc: 0.49335\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.502069  [    0/40000]\n",
            "loss: 1.276432  [ 6400/40000]\n",
            "loss: 1.534292  [12800/40000]\n",
            "loss: 1.270739  [19200/40000]\n",
            "loss: 1.151525  [25600/40000]\n",
            "loss: 1.347584  [32000/40000]\n",
            "loss: 1.417330  [38400/40000]\n",
            "train loss: 1.2955830062866212, train_acc: 0.5399\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.199123  [    0/40000]\n",
            "loss: 1.323167  [ 6400/40000]\n",
            "loss: 1.121469  [12800/40000]\n",
            "loss: 1.071427  [19200/40000]\n",
            "loss: 1.219332  [25600/40000]\n",
            "loss: 1.552676  [32000/40000]\n",
            "loss: 1.173624  [38400/40000]\n",
            "train loss: 1.1984726869583129, train_acc: 0.574325\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.080025  [    0/40000]\n",
            "loss: 0.830977  [ 6400/40000]\n",
            "loss: 1.274537  [12800/40000]\n",
            "loss: 1.114810  [19200/40000]\n",
            "loss: 1.194664  [25600/40000]\n",
            "loss: 1.260646  [32000/40000]\n",
            "loss: 1.028244  [38400/40000]\n",
            "train loss: 1.1102063075065614, train_acc: 0.607825\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.207138  [    0/40000]\n",
            "loss: 0.986998  [ 6400/40000]\n",
            "loss: 0.671108  [12800/40000]\n",
            "loss: 1.182474  [19200/40000]\n",
            "loss: 0.937907  [25600/40000]\n",
            "loss: 0.980893  [32000/40000]\n",
            "loss: 0.705180  [38400/40000]\n",
            "train loss: 1.038252069759369, train_acc: 0.631475\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.998581  [    0/40000]\n",
            "loss: 0.989930  [ 6400/40000]\n",
            "loss: 1.096901  [12800/40000]\n",
            "loss: 0.869017  [19200/40000]\n",
            "loss: 1.240999  [25600/40000]\n",
            "loss: 1.346110  [32000/40000]\n",
            "loss: 0.849558  [38400/40000]\n",
            "train loss: 0.9566093987464904, train_acc: 0.661475\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.994379  [    0/40000]\n",
            "loss: 0.815755  [ 6400/40000]\n",
            "loss: 0.845779  [12800/40000]\n",
            "loss: 0.692816  [19200/40000]\n",
            "loss: 0.975112  [25600/40000]\n",
            "loss: 0.980463  [32000/40000]\n",
            "loss: 0.854266  [38400/40000]\n",
            "train loss: 0.886098732662201, train_acc: 0.686275\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.738540  [    0/40000]\n",
            "loss: 0.921448  [ 6400/40000]\n",
            "loss: 0.726769  [12800/40000]\n",
            "loss: 0.785658  [19200/40000]\n",
            "loss: 0.709607  [25600/40000]\n",
            "loss: 0.952568  [32000/40000]\n",
            "loss: 1.194847  [38400/40000]\n",
            "train loss: 0.8153765149593353, train_acc: 0.712725\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.725621  [    0/40000]\n",
            "loss: 0.665055  [ 6400/40000]\n",
            "loss: 0.605769  [12800/40000]\n",
            "loss: 0.885786  [19200/40000]\n",
            "loss: 0.569978  [25600/40000]\n",
            "loss: 0.752421  [32000/40000]\n",
            "loss: 0.821710  [38400/40000]\n",
            "train loss: 0.7475587015628815, train_acc: 0.7398\n",
            "Done!\n",
            "Training time: 58.084710121154785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht7xElaC6mLj"
      },
      "source": [
        "We keep on improving! You should have an accuracy of 0.73, which shows that SGD with momentum steps faster towards the global minimum than vanilla mini-batch gradient descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU3qmRw57c8N"
      },
      "source": [
        "###Adam\n",
        "We will skip RMSProp and use the Adam optimizer directly, which is usually the *de facto* standard in deep learning. Adam usually benefits from smaller learning rates, so we will decrease it to $10^{-4}$.\n",
        "\n",
        "**EXERCISE:** use Adam with default parameter values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CywjelPu7en0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "856a4c05-566e-486c-80d8-2e9de713e49a"
      },
      "source": [
        "import time\n",
        "\n",
        "learning_rate = 1e-4 # Decrease the learning rate\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(0)\n",
        "\n",
        "model = MyMLPBN()\n",
        "model = model.to(device)\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_losses, train_accuracies  = [], []\n",
        "start = time.time()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss, train_acc = train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
        "    print(f'train loss: {train_loss}, train_acc: {train_acc}')\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)    \n",
        "end = time.time()\n",
        "print(\"Done!\")\n",
        "print(f'Training time: {end-start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.817509  [    0/40000]\n",
            "loss: 1.810218  [ 6400/40000]\n",
            "loss: 1.538449  [12800/40000]\n",
            "loss: 1.541885  [19200/40000]\n",
            "loss: 1.408666  [25600/40000]\n",
            "loss: 1.488074  [32000/40000]\n",
            "loss: 1.639456  [38400/40000]\n",
            "train loss: 1.6729518020629883, train_acc: 0.4125\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.552140  [    0/40000]\n",
            "loss: 1.356066  [ 6400/40000]\n",
            "loss: 1.284702  [12800/40000]\n",
            "loss: 1.621797  [19200/40000]\n",
            "loss: 1.321322  [25600/40000]\n",
            "loss: 1.304420  [32000/40000]\n",
            "loss: 1.272212  [38400/40000]\n",
            "train loss: 1.4105005314826966, train_acc: 0.505225\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.373138  [    0/40000]\n",
            "loss: 1.277865  [ 6400/40000]\n",
            "loss: 1.374313  [12800/40000]\n",
            "loss: 1.344787  [19200/40000]\n",
            "loss: 1.213401  [25600/40000]\n",
            "loss: 1.311934  [32000/40000]\n",
            "loss: 1.270326  [38400/40000]\n",
            "train loss: 1.2881783643722535, train_acc: 0.550975\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.196358  [    0/40000]\n",
            "loss: 1.312873  [ 6400/40000]\n",
            "loss: 1.028398  [12800/40000]\n",
            "loss: 1.157699  [19200/40000]\n",
            "loss: 1.200544  [25600/40000]\n",
            "loss: 1.410328  [32000/40000]\n",
            "loss: 1.247777  [38400/40000]\n",
            "train loss: 1.1979286383628844, train_acc: 0.58755\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.118153  [    0/40000]\n",
            "loss: 0.978735  [ 6400/40000]\n",
            "loss: 1.217828  [12800/40000]\n",
            "loss: 1.070336  [19200/40000]\n",
            "loss: 1.277589  [25600/40000]\n",
            "loss: 1.318428  [32000/40000]\n",
            "loss: 1.118895  [38400/40000]\n",
            "train loss: 1.120414851951599, train_acc: 0.616225\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.211763  [    0/40000]\n",
            "loss: 1.009776  [ 6400/40000]\n",
            "loss: 0.751943  [12800/40000]\n",
            "loss: 1.070673  [19200/40000]\n",
            "loss: 0.970263  [25600/40000]\n",
            "loss: 0.907715  [32000/40000]\n",
            "loss: 0.794967  [38400/40000]\n",
            "train loss: 1.0485243931770325, train_acc: 0.6403\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.038967  [    0/40000]\n",
            "loss: 1.108810  [ 6400/40000]\n",
            "loss: 1.000590  [12800/40000]\n",
            "loss: 0.829820  [19200/40000]\n",
            "loss: 1.158430  [25600/40000]\n",
            "loss: 1.283481  [32000/40000]\n",
            "loss: 1.018707  [38400/40000]\n",
            "train loss: 0.9807564351081848, train_acc: 0.669975\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.068809  [    0/40000]\n",
            "loss: 0.947201  [ 6400/40000]\n",
            "loss: 0.897182  [12800/40000]\n",
            "loss: 0.819906  [19200/40000]\n",
            "loss: 1.026417  [25600/40000]\n",
            "loss: 0.847466  [32000/40000]\n",
            "loss: 0.889063  [38400/40000]\n",
            "train loss: 0.9197845933914185, train_acc: 0.6906\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.754191  [    0/40000]\n",
            "loss: 0.944358  [ 6400/40000]\n",
            "loss: 0.703917  [12800/40000]\n",
            "loss: 0.804776  [19200/40000]\n",
            "loss: 0.843467  [25600/40000]\n",
            "loss: 0.940608  [32000/40000]\n",
            "loss: 1.133340  [38400/40000]\n",
            "train loss: 0.860831706905365, train_acc: 0.715025\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.731247  [    0/40000]\n",
            "loss: 0.770683  [ 6400/40000]\n",
            "loss: 0.727047  [12800/40000]\n",
            "loss: 0.766282  [19200/40000]\n",
            "loss: 0.823596  [25600/40000]\n",
            "loss: 0.685846  [32000/40000]\n",
            "loss: 0.847989  [38400/40000]\n",
            "train loss: 0.8049688938140869, train_acc: 0.734725\n",
            "Done!\n",
            "Training time: 60.18989896774292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2hs5gHu7zfM"
      },
      "source": [
        "Well, we obtain a very similar train accuracy with Adam, i.e. around 0.73. Although it would be better to explore learning rate values more exhaustively (random search), let's stick to Adam with lr=1e-4 and train for more epochs, as the training accuracy is still improving. In the following cell you have the code to train our model for **30 epochs more** with the Adam optimizer, up to a total of 40 epochs. Look carefully at the code: as the state of `model` and `optimizer` are still stored in the session of Colab, we can resume the training process from the last epoch (epoch number 10)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0UzwRxB_L76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49d674c9-27d7-4271-96f7-254acb50cadc"
      },
      "source": [
        "import time\n",
        "\n",
        "start_epoch = 10 # Resume from the last training point\n",
        "epochs = 30 # Add more epochs to our training\n",
        "start = time.time()\n",
        "for t in range(start_epoch, start_epoch+epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss, train_acc = train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
        "    print(f'train loss: {train_loss}, train_acc: {train_acc}')\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)    \n",
        "end = time.time()\n",
        "print(\"Done!\")\n",
        "print(f'Training time: {end-start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.622193  [    0/40000]\n",
            "loss: 0.738723  [ 6400/40000]\n",
            "loss: 0.617285  [12800/40000]\n",
            "loss: 0.775634  [19200/40000]\n",
            "loss: 0.777743  [25600/40000]\n",
            "loss: 0.947315  [32000/40000]\n",
            "loss: 0.948309  [38400/40000]\n",
            "train loss: 0.7544095659255982, train_acc: 0.75245\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.840802  [    0/40000]\n",
            "loss: 0.599306  [ 6400/40000]\n",
            "loss: 0.837370  [12800/40000]\n",
            "loss: 0.597579  [19200/40000]\n",
            "loss: 0.833388  [25600/40000]\n",
            "loss: 0.769967  [32000/40000]\n",
            "loss: 0.863696  [38400/40000]\n",
            "train loss: 0.7040151552677154, train_acc: 0.772975\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.501136  [    0/40000]\n",
            "loss: 0.684153  [ 6400/40000]\n",
            "loss: 0.605208  [12800/40000]\n",
            "loss: 0.699424  [19200/40000]\n",
            "loss: 0.807079  [25600/40000]\n",
            "loss: 0.822349  [32000/40000]\n",
            "loss: 0.715560  [38400/40000]\n",
            "train loss: 0.6557228041172027, train_acc: 0.79005\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.608105  [    0/40000]\n",
            "loss: 0.543675  [ 6400/40000]\n",
            "loss: 0.607903  [12800/40000]\n",
            "loss: 0.563818  [19200/40000]\n",
            "loss: 0.651510  [25600/40000]\n",
            "loss: 0.621941  [32000/40000]\n",
            "loss: 0.691623  [38400/40000]\n",
            "train loss: 0.6078489591121674, train_acc: 0.810475\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.526985  [    0/40000]\n",
            "loss: 0.431936  [ 6400/40000]\n",
            "loss: 0.591443  [12800/40000]\n",
            "loss: 0.467728  [19200/40000]\n",
            "loss: 0.554411  [25600/40000]\n",
            "loss: 0.655631  [32000/40000]\n",
            "loss: 0.599276  [38400/40000]\n",
            "train loss: 0.569548184967041, train_acc: 0.82075\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.485560  [    0/40000]\n",
            "loss: 0.512517  [ 6400/40000]\n",
            "loss: 0.595035  [12800/40000]\n",
            "loss: 0.621207  [19200/40000]\n",
            "loss: 0.793157  [25600/40000]\n",
            "loss: 0.574262  [32000/40000]\n",
            "loss: 0.564154  [38400/40000]\n",
            "train loss: 0.5361656604766846, train_acc: 0.833275\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.500059  [    0/40000]\n",
            "loss: 0.448401  [ 6400/40000]\n",
            "loss: 0.419039  [12800/40000]\n",
            "loss: 0.530223  [19200/40000]\n",
            "loss: 0.525397  [25600/40000]\n",
            "loss: 0.471446  [32000/40000]\n",
            "loss: 0.559060  [38400/40000]\n",
            "train loss: 0.49058201355934145, train_acc: 0.850575\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.414690  [    0/40000]\n",
            "loss: 0.462319  [ 6400/40000]\n",
            "loss: 0.504684  [12800/40000]\n",
            "loss: 0.494914  [19200/40000]\n",
            "loss: 0.386554  [25600/40000]\n",
            "loss: 0.390572  [32000/40000]\n",
            "loss: 0.453747  [38400/40000]\n",
            "train loss: 0.4607646236419678, train_acc: 0.860025\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.319503  [    0/40000]\n",
            "loss: 0.436232  [ 6400/40000]\n",
            "loss: 0.404167  [12800/40000]\n",
            "loss: 0.331437  [19200/40000]\n",
            "loss: 0.553519  [25600/40000]\n",
            "loss: 0.315268  [32000/40000]\n",
            "loss: 0.361810  [38400/40000]\n",
            "train loss: 0.42215129141807556, train_acc: 0.873675\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.419896  [    0/40000]\n",
            "loss: 0.399239  [ 6400/40000]\n",
            "loss: 0.298874  [12800/40000]\n",
            "loss: 0.316381  [19200/40000]\n",
            "loss: 0.415060  [25600/40000]\n",
            "loss: 0.382529  [32000/40000]\n",
            "loss: 0.335871  [38400/40000]\n",
            "train loss: 0.39334219024181366, train_acc: 0.88265\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.418490  [    0/40000]\n",
            "loss: 0.354767  [ 6400/40000]\n",
            "loss: 0.247357  [12800/40000]\n",
            "loss: 0.369909  [19200/40000]\n",
            "loss: 0.418494  [25600/40000]\n",
            "loss: 0.434011  [32000/40000]\n",
            "loss: 0.461153  [38400/40000]\n",
            "train loss: 0.36923584253787994, train_acc: 0.890925\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.382308  [    0/40000]\n",
            "loss: 0.279358  [ 6400/40000]\n",
            "loss: 0.267978  [12800/40000]\n",
            "loss: 0.418180  [19200/40000]\n",
            "loss: 0.230450  [25600/40000]\n",
            "loss: 0.334021  [32000/40000]\n",
            "loss: 0.460277  [38400/40000]\n",
            "train loss: 0.3457314817428589, train_acc: 0.900275\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.263469  [    0/40000]\n",
            "loss: 0.283766  [ 6400/40000]\n",
            "loss: 0.436927  [12800/40000]\n",
            "loss: 0.430730  [19200/40000]\n",
            "loss: 0.234081  [25600/40000]\n",
            "loss: 0.369569  [32000/40000]\n",
            "loss: 0.369680  [38400/40000]\n",
            "train loss: 0.32929820688962935, train_acc: 0.904575\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.192039  [    0/40000]\n",
            "loss: 0.283804  [ 6400/40000]\n",
            "loss: 0.370048  [12800/40000]\n",
            "loss: 0.325509  [19200/40000]\n",
            "loss: 0.191608  [25600/40000]\n",
            "loss: 0.381187  [32000/40000]\n",
            "loss: 0.329515  [38400/40000]\n",
            "train loss: 0.30017775537967684, train_acc: 0.914575\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.372023  [    0/40000]\n",
            "loss: 0.269844  [ 6400/40000]\n",
            "loss: 0.187648  [12800/40000]\n",
            "loss: 0.290636  [19200/40000]\n",
            "loss: 0.400905  [25600/40000]\n",
            "loss: 0.226548  [32000/40000]\n",
            "loss: 0.239132  [38400/40000]\n",
            "train loss: 0.2761818579673767, train_acc: 0.92395\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.234875  [    0/40000]\n",
            "loss: 0.190711  [ 6400/40000]\n",
            "loss: 0.195301  [12800/40000]\n",
            "loss: 0.347752  [19200/40000]\n",
            "loss: 0.315344  [25600/40000]\n",
            "loss: 0.277825  [32000/40000]\n",
            "loss: 0.225426  [38400/40000]\n",
            "train loss: 0.25953965088129044, train_acc: 0.92885\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.294648  [    0/40000]\n",
            "loss: 0.269679  [ 6400/40000]\n",
            "loss: 0.196834  [12800/40000]\n",
            "loss: 0.253393  [19200/40000]\n",
            "loss: 0.275134  [25600/40000]\n",
            "loss: 0.237255  [32000/40000]\n",
            "loss: 0.258060  [38400/40000]\n",
            "train loss: 0.24696246938705443, train_acc: 0.9306\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.184143  [    0/40000]\n",
            "loss: 0.201801  [ 6400/40000]\n",
            "loss: 0.148974  [12800/40000]\n",
            "loss: 0.235866  [19200/40000]\n",
            "loss: 0.247228  [25600/40000]\n",
            "loss: 0.278535  [32000/40000]\n",
            "loss: 0.148012  [38400/40000]\n",
            "train loss: 0.23572570111751556, train_acc: 0.93425\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.247680  [    0/40000]\n",
            "loss: 0.209011  [ 6400/40000]\n",
            "loss: 0.201892  [12800/40000]\n",
            "loss: 0.141988  [19200/40000]\n",
            "loss: 0.276937  [25600/40000]\n",
            "loss: 0.235373  [32000/40000]\n",
            "loss: 0.250356  [38400/40000]\n",
            "train loss: 0.22375843713283539, train_acc: 0.93875\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.195734  [    0/40000]\n",
            "loss: 0.153379  [ 6400/40000]\n",
            "loss: 0.145348  [12800/40000]\n",
            "loss: 0.161495  [19200/40000]\n",
            "loss: 0.239429  [25600/40000]\n",
            "loss: 0.228909  [32000/40000]\n",
            "loss: 0.270203  [38400/40000]\n",
            "train loss: 0.20873590284585952, train_acc: 0.94175\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.195259  [    0/40000]\n",
            "loss: 0.063959  [ 6400/40000]\n",
            "loss: 0.162429  [12800/40000]\n",
            "loss: 0.133734  [19200/40000]\n",
            "loss: 0.265668  [25600/40000]\n",
            "loss: 0.178225  [32000/40000]\n",
            "loss: 0.139950  [38400/40000]\n",
            "train loss: 0.195621923327446, train_acc: 0.946425\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.171543  [    0/40000]\n",
            "loss: 0.305097  [ 6400/40000]\n",
            "loss: 0.144498  [12800/40000]\n",
            "loss: 0.241350  [19200/40000]\n",
            "loss: 0.301000  [25600/40000]\n",
            "loss: 0.182286  [32000/40000]\n",
            "loss: 0.173717  [38400/40000]\n",
            "train loss: 0.18703899335861207, train_acc: 0.94925\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.181754  [    0/40000]\n",
            "loss: 0.191304  [ 6400/40000]\n",
            "loss: 0.127953  [12800/40000]\n",
            "loss: 0.155974  [19200/40000]\n",
            "loss: 0.173673  [25600/40000]\n",
            "loss: 0.085369  [32000/40000]\n",
            "loss: 0.251196  [38400/40000]\n",
            "train loss: 0.16843481679558753, train_acc: 0.957125\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.114398  [    0/40000]\n",
            "loss: 0.089855  [ 6400/40000]\n",
            "loss: 0.137191  [12800/40000]\n",
            "loss: 0.242255  [19200/40000]\n",
            "loss: 0.216730  [25600/40000]\n",
            "loss: 0.162888  [32000/40000]\n",
            "loss: 0.166577  [38400/40000]\n",
            "train loss: 0.16902780153155328, train_acc: 0.953375\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.190787  [    0/40000]\n",
            "loss: 0.134692  [ 6400/40000]\n",
            "loss: 0.197257  [12800/40000]\n",
            "loss: 0.192703  [19200/40000]\n",
            "loss: 0.224605  [25600/40000]\n",
            "loss: 0.168697  [32000/40000]\n",
            "loss: 0.151976  [38400/40000]\n",
            "train loss: 0.15647177548408508, train_acc: 0.957925\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.172851  [    0/40000]\n",
            "loss: 0.158219  [ 6400/40000]\n",
            "loss: 0.115828  [12800/40000]\n",
            "loss: 0.139237  [19200/40000]\n",
            "loss: 0.280517  [25600/40000]\n",
            "loss: 0.121575  [32000/40000]\n",
            "loss: 0.170824  [38400/40000]\n",
            "train loss: 0.15354651235342026, train_acc: 0.958575\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.192797  [    0/40000]\n",
            "loss: 0.088288  [ 6400/40000]\n",
            "loss: 0.140878  [12800/40000]\n",
            "loss: 0.122230  [19200/40000]\n",
            "loss: 0.167145  [25600/40000]\n",
            "loss: 0.191168  [32000/40000]\n",
            "loss: 0.137044  [38400/40000]\n",
            "train loss: 0.14538216162323953, train_acc: 0.9616\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.238758  [    0/40000]\n",
            "loss: 0.182289  [ 6400/40000]\n",
            "loss: 0.054236  [12800/40000]\n",
            "loss: 0.218882  [19200/40000]\n",
            "loss: 0.103775  [25600/40000]\n",
            "loss: 0.154320  [32000/40000]\n",
            "loss: 0.162797  [38400/40000]\n",
            "train loss: 0.13970248371958732, train_acc: 0.962675\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.102630  [    0/40000]\n",
            "loss: 0.191697  [ 6400/40000]\n",
            "loss: 0.114974  [12800/40000]\n",
            "loss: 0.121919  [19200/40000]\n",
            "loss: 0.123473  [25600/40000]\n",
            "loss: 0.200025  [32000/40000]\n",
            "loss: 0.209323  [38400/40000]\n",
            "train loss: 0.1334100157380104, train_acc: 0.964525\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.150891  [    0/40000]\n",
            "loss: 0.128884  [ 6400/40000]\n",
            "loss: 0.126543  [12800/40000]\n",
            "loss: 0.142216  [19200/40000]\n",
            "loss: 0.218792  [25600/40000]\n",
            "loss: 0.180861  [32000/40000]\n",
            "loss: 0.137470  [38400/40000]\n",
            "train loss: 0.1291020056784153, train_acc: 0.96585\n",
            "Done!\n",
            "Training time: 182.18013954162598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fERgMcK-IXI"
      },
      "source": [
        "Wow! We achieve **0.96 accuracy** in training (very-very close to 0.97). Let me remember that the frist trial we made with the same neural network architecture achieved 0.29 accuracy. Thus, changing weight initialization, including batch normalization, tweaking a bit the learning rate, using Adam and increasing the epochs, we have now 0.96 accuracy. So **deep learning is not just about adding layers and neurons**. There are many techniques and approaches that can dramatically change the behaviour of the same neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snFdhPmN-zlS"
      },
      "source": [
        "To have a better idea of how the training process went, let's look at training learning curves for loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq_WcKEjAz1C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "7cbeb7f6-de76-4820-c7ce-67b6bc77adad"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = start_epoch + epochs\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(epochs), train_losses, color='blue', label='train')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(epochs), train_accuracies, color='blue', label='train')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debyV4/7/8den2skQUnE0KEMoDkUyH7NfMpRZxkxxzGTI6XzjlPFwzDrJlGOIDBEyRsY0IEMl4qBdUVIpmn1+f1xrs0/2sKp9r+tea72fj8d67DXcrfXerXXvz7qv+xrM3REREUmbWrEDiIiIVEQFSkREUkkFSkREUkkFSkREUkkFSkREUqlO7AArqlGjRt6yZcvYMaRIvf/++z+4e+PYOWqC9iWJKZt9Ke8KVMuWLRk7dmzsGFKkzOyb2BlqivYliSmbfUlNfCIikkoqUCIikkoqUCIikkp5dw5K4lqyZAmlpaUsXLgwdpRE1atXj2bNmlFSUhI7Sk7p/ZU0UYGSFVJaWkr9+vVp2bIlZhY7TiLcnVmzZlFaWsrGG28cO05O6f2VNFETn6yQhQsX0rBhw4L94wVgZjRs2LDgjyIqovdX0kQFSlZYIf/xKlMMv2NliuF3L4bfsRCoQImISCoVTIH64AM4+mj4739jJ5EkzZkzh379+q3wv+vUqRNz5sxJIJHUJL2/+ckdSkvhtdfg7ruhZ0848kiYOnXVnrdgOknMmweDB8Ppp4POexausj9gZ5111v/cv3TpUurUqfzjPGzYsKSjSQ3Q+5tuv/wCU6aEYjRlCkycGA4OPvwQZs36fbuSEmjZEmbOhKZNV/71CqZAlf0nTJsWN4ckq2fPnnz55Ze0bduWkpIS6tWrR4MGDfjss8/4/PPP6dKlC1OmTGHhwoWcf/75dO/eHfh9Wp/58+dzwAEHsNtuu/Huu+/StGlTnnnmGVZfffXIv5mA3t+0cYdPPoGnn4YhQ2DcuP99vG5d2Hpr6NIF2rWDLbeETTeF5s2hdu1Vf/2CKVAbbhh+qkDlzgUX/PEDu6ratoVbbqn88euuu45PP/2UcePGMWLECA488EA+/fTT37oL33fffay33nosWLCAHXbYgcMPP5yGDRv+z3N88cUXDBo0iLvvvpujjjqKJ598kuOPP75mf5ECoPe38CxeDJ9/Dm3aQK3lTvB8/z0MGBAenz07XKZMCRcz2GUX6NMntFA1bw7NmoWfdesml7dgCtSaa8I666hAFZsOHTr8z1iW2267jSFDhgAwZcoUvvjiiz/8Adt4441p27YtANtvvz1ff/11zvLKitH7W3OmT4dDD4VRo6BFCzjlFDj5ZFi2DG64Ae67DxYtCk1zDRqEy667wt57wyGHwAYb5D5zwRQogCZNVv2knGSvqm/CubLmmmv+dn3EiBG8+uqrjBw5kjXWWIM999yzwrEuq6222m/Xa9euzYIFC3KSNd/o/S0cY8aEZri5c+Gqq+CNN+CKK+DKK8ORVK1acNJJcOml0KpV7LS/K6gC1bSpjqAKXf369Zk3b16Fj82dO5cGDRqwxhpr8Nlnn/Hee+/lOJ2sKr2/NWvZMnjwQTjzzHAa5N13YZttoFev0OP5gQdgyRI466xV68yQlIIqUE2awIgRsVNIkho2bMiuu+7K1ltvzeqrr84G5dodOnbsSP/+/WndujVbbLEFO+20U8SksjL0/q662bPhhRfg+efhxRfhxx9hzz3h8cehUaPft9t443AElWrunsgFuA+YAXxaxTZ7AuOA8cAb2Tzv9ttv75Xp2dO9pMR92bJKN5FVNGHChNgRcqai3xUY6wntM7m+VLQvFfv7m8+mTXO/6CL3NdZwB/fGjd1POsl98GD3xYtjp/ujbPalJI+gBgJ3AP+p6EEzWxfoB3R092/NbP1VfcEmTcLh6g8/wPqr/GwiIunmHsYi3Xkn3HsvLF0Kxx4bmuw6dPhjT718k1iBcvc3zaxlFZscCzzl7t9mtp+xqq9ZfiyUCpSIFCL3cC7p6afhmWfgiy/CwNiTT4bLLoNNNomdsObErK+bAw3MbISZvW9mJ1a2oZl1N7OxZjZ25syZlT5hkybhpzpKJCscnRe2YvgdK1MMv3s+/o5Ll8Ijj4QBsbvtBrfeGopRv37wzTdw112FVZwgbieJOsD2wD7A6sBIM3vP3T9ffkN3HwAMAGjfvn2lnywVqOTVq1ePWbNmFfSSDJ5ZL6hevXqxo+Sc3t/0mT0bHnoIbroJvv4aWrcOzXmHHx7GfhaymAWqFJjl7j8DP5vZm8C2wB8KVLb+9KfwU2OhktOsWTNKS0up6ki2EJStuFps9P6mw7JlMHw43H9/mGJo0SLYeedw1HTQQfl/bilbMQvUM8AdZlYHqAvsCNy8Kk9Yt24496QjqOSUlJRoFdICpvc3ju++C+eTPv4YPvoo/Jw3L8zmcPrp4fxSu3ZhyqFikliBMrNBhG7kjcysFLgCKAFw9/7uPtHMXgQ+Bn4F7nH3T1f1dZs0UYESkfwwYwZcf304j7RwIay9dhhIe+KJsMceYYqhchNjFJ0ke/F1zWKbG4AbavJ1VaBEJO0WLgyDZG+/PVw/4YQwzVDr1sV3lFSVgppJAkKBev/92ClERCr2yy/QuTO8+iocdxz07g2bbx47VToVZIGaMSMM2C0piZ1GROR38+eHTg5vvQUDB4YJWqVyBdcXpGnTMJDt++9jJxER+d3cufD//h+8/XboNq7iVL2CK1AaCyUiaTN3Luy/P4weDY89Bl2rPUMvUKBNfKACJSLpMH8+dOoEH3wATz4ZeuZJdgq2QGmwrojEtmBBKEijRoUjJxWnFVNwTXzrrw+1a+sISgqHmXU0s0lmNtnMelbweAszG25mH2fmtkzvFAlFZNGisMT6iBHwn/+EqYlkxRRcgapVK6wcqQIlhcDMagN3AgcAbYCuZtZmuc1uBP7j7tsAfYBrc5tSylu6FAYPhl12gZdegnvuCUtgyIoruAIFGqwrBaUDMNndv3L3xcCjQOfltmkDvJa5/noFj0sOLFgQJnTddFM4+mj46ScYNAhOOSV2svxVsAVK56CkQDQFppS7XZq5r7yPgMMy1w8F6ptZwxxkk4x586BjR+jRA1q2DGs1ffYZHHNM7GT5rSALVNOmOoKSonIxsIeZfQjsAUwFllW0YbZrq0n2ysY3vfNOWK/pjTfCTBG1a8dOlv8KskA1aRLWUFmwIHYSkVU2FWhe7nazzH2/cfdp7n6Yu7cDemXum1PRk7n7AHdv7+7tGzdunFTmovHjj7DvvjB2LDz+uMY31bSCLVAA06fHzSFSA8YArcxsYzOrCxwDDC2/gZk1MrOyffly4L4cZyxK06fD3nvDJ5+ENZsOPTR2osJT0AVK56Ek37n7UuAc4CVgIjDY3cebWR8zKxtVsycwycw+BzYAro4Stoh88gnsuCNMngzPPgsHHhg7UWEquIG6EM5Bgc5DSWFw92HAsOXu613u+hPAE7nOVaxeegmOPBLq1w+TvrZrFztR4SroIygVKBGpSQMGhKOlTTYJs0OoOCWrIAvUuutCvXoqUCJSM9zhqqvgjDNCj7233oJmmq8jcQXZxGemsVAiUjPc4eKLwyDcE06A++6DOgX5lzN9CvIICjSbhIisuqVL4dRTQ3E699ywyKCKU+4kVqDM7D4zm2Fmn1az3Q5mttTMjqjJ19dgXRFZVWefDfffD1deCbfeGub6lNxJ8r97INCxqg0yE2FeD7xc0y/evDlMmRK+AYmIrKghQ0KniEsvhSuuCKcOJLcSK1Du/ibwYzWbnQs8Ccyo6dfffntYuDCMVxARWRHTpsFpp4W/I337xk5TvKIdsJpZU8LElv/OYtsVnj9sp53Cz/feW4WQIlJ0fv0VunULX3Affhjq1o2dqHjFbFG9BbjM3X+tbsOVmT+sRQvYYAMYOXJVY4pIMbntNnjlldAxYostYqcpbjH7o7QHHrXQsNsI6GRmS9396Zp4cjPYeWcdQYlI9saMgZ494eCDoXv32Gkk2hGUu2/s7i3dvSVhmpazaqo4ldlpJ/jiC5g1qyafVUQK0ahRsN9+YUXue+5Rp4g0SLKb+SBgJLCFmZWa2almdqaZnZnUay6v7DzUqFG5ekURyUfvvBOKU6NG8OabsP76sRMJJNjE5+5Zr4zi7t2SyNC+fVg0bORI6NQpiVcQkXz35pvh70PTpvDaa79PNi3xFfSwszXXhG220XkoEanYN9+E4rTRRjBihIpT2hR0gYLQzDdqFCyrcAFsESlmf/tb+Nvw4ovh3JOkS1EUqHnzYOLE2ElEJE3GjIFHHoGLLgpHUJI+BV+gdt45/FQzn4iUcYcePUJniJ49Y6eRyhR8gdpsM1hvPRUoEfndM8+ENZ3+8Y+wMq6kU8EXKLPQzKcZJUQEYPHiMAFsmzZhvj1Jr4IvUBAK1IQJMGdO7CQiElv//mEA/w03aG2ntCuKAlV2HmrMmLg5RCSuzz6DXr1g333hgANip5HqFEWB2mGH0NSnZj6R4vXzz3DEEVCvXliEUFMZpV9RHOCusw5svXUYMS4ixccdzjgjNPW//DI0axY7kWSjKI6gADp2DAXqp59iJxGRXOvfP6zt1KdPaN6T/FA0Beqgg2DJkvDtSUSKx6hRcP75YUqjv/0tdhpZEUVToHbZBRo0gOeei51ERHJlwgQ48MDQpPfgg1CraP7iFYaiebvq1Am9doYN07x8IsXgv/8NS2iUlISWk/XWi51IVlTRFCgIzXwzZ8Lo0bGTiEiSpk8P55oWLAjFabPNYieSlVFUBapjx7A+lJr5RArX3LnhyOn77+GFF+DPf46dSFZWURWoBg1gt93g2WdjJxGRpNx2G4wfD08/DTvuGDuNrIqiKlAQmvk++SQsVCaSL8yso5lNMrPJZvaH+bfNbCMze93MPjSzj82sKNeQ/vlnuPXWsJ+rO3n+S6xAmdl9ZjbDzD6t5PHjMjvSJ2b2rpltm1SW8g4+OPx8/vlcvJrIqjOz2sCdwAFAG6CrmbVZbrO/A4PdvR1wDNAvtynT4Z57YNYsuPzy2EmkJiR5BDUQ6FjF4/8F9nD3PwN9gQEJZvnN5puHE6Zq5pM80gGY7O5fufti4FGg83LbOLB25vo6wLQc5kuFxYvhxhvhL38Jw0ok/yVWoNz9TeDHKh5/191nZ26+B+Rk8hGzcPj/2mswf34uXlFklTUFppS7XZq5r7wrgePNrBQYBpxb0ROZWXczG2tmY2fOnJlE1mgefhhKS7UAYSFJyzmoU4EXcvViBx8cvm29+mquXlEkcV2Bge7eDOgEPGhmf9i/3X2Au7d39/aNGzfOecikLFsG118PbduG3rpSGKIXKDPbi1CgLqtimxr91rf77mHQ3uDBq/xUIrkwFWhe7nazzH3lnQoMBnD3kUA9oFFO0qXA00/DpEnh6EmzlBeOqAXKzLYB7gE6u/usyrar6W99JSVh2v1nngm9fkRSbgzQysw2NrO6hE4QQ5fb5ltgHwAza00oUIXVhlcJd7j22nBu+YgjYqeRmhStQJnZRsBTwAnu/nmuX79rV/jlFw3alfRz96XAOcBLwERCb73xZtbHzA7JbNYDON3MPgIGAd3c3eMkzq3HH4f33w8992rXjp1GapIl9Rk2s0HAnoRmhu+BK4ASAHfvb2b3AIcDZSOSlrp7++qet3379j527NhVzrdsGTRvDh06hOYBkWyY2fvZfE7zQU3tSzEtXAitW4c1395/XwUqn2SzLyW2YKG7d63m8dOA05J6/erUrg1HHw39+sGcObDuurGSiMjKuuUW+Prr0OFJxanwRO8kEVPXrqE331NPxU4iIivq++/hmmtCr9x99omdRpJQ1AVqhx1g001h0KDYSURkRfXuHWYrv+GG2EkkKUVdoMzgmGPCoN3vv4+dRkSy9cknYVqjs86CLbaInUaSUtQFCkIz36+/hp5AIpIfevYMHSOuuCJ2EklS0ReorbYK68WomU8kP3z0UVgZu0cPrZJb6Iq+QEFo5nv33bBEtIik2/XXQ/36cPbZsZNI0lSggOOPD+ejHnwwdhIRqcqXX8Jjj8GZZ2poSDFQgQI22gj22gseeCBMmyIi6XTjjVCnDlxwQewkkgsqUBndusFXX8Hbb8dOIiIV+e47uP9+OOkkaNIkdhrJBRWojMMOg7XWgoEDYycRkYrceissWQKXXho7ieSKClTGmmvCUUeFJTg0w7lIusydG6YlO+KIMGu5FAcVqHJOOimssjtkSOwkIlLebbfBTz/BZZWuGieFSAWqnN12g002UTOfSJrMmBGmM+rSBbbbLnYaySUVqHJq1QpHUa+9Bt98U/32IpK8vn3D2m3XXhs7ieSaCtRyTjwxdDXXmCiR+CZPhv794bTTYMstY6eRXFOBWk7LlmFM1MCBYY4+EYmnVy+oW1dz7hUrFagKnHpqGLE+YkTsJFJIzOwpMzvQzLTfZWH06NCr9uKLYcMNY6eRGLSjVODww6FBAxgwIHYSKTD9gGOBL8zsOjPTQhGVcA/jndZfPxQoKU4qUBWoVy+cixoyBGbOjJ1GCoW7v+ruxwHbAV8Dr5rZu2Z2spmVxE2XLq+8Am+8ERYlrF8/dhqJJbECZWb3mdkMM/u0ksfNzG4zs8lm9rGZpaoD6emnh+Xg//Of2EmkkJhZQ6AbcBrwIXAroWC9EjFWqrhDnz7QrFnoHCHFK8kjqIFAxyoePwBolbl0B/6dYJYVttVWsMsucPfdmkBWaoaZDQHeAtYADnb3Q9z9MXc/F1grbrr0GDEC3nknDMpdbbXYaSSmxAqUu78J/FjFJp2B/3jwHrCumaXqVGj37jBpErz1VuwkUiBuc/c27n6tu08v/4C7t48VKm369g2dInT0JDHPQTUFppS7XZq57w/MrLuZjTWzsTNzeFLoyCPDstLqLCE1pI2Z/baKkZk1MLOzYgZKm3fegddfh0suCeeCpbjlRScJdx/g7u3dvX3jxo1z9rprrBEWM3ziCfixqmNBkeyc7u5zym64+2zg9Ih5UqdvX2jcGM44I3YSSYOYBWoq0Lzc7WaZ+1Ll9NNh0SJ1lpAaUdvMrOyGmdUG6kbMkyqjR8NLL0GPHuHLoUjMAjUUODHTm28nYO7y7fJpsO22sPPOcMcdsGxZ7DSS514EHjOzfcxsH2BQ5j4hHD2ttx6cpUZPyUiym/kgYCSwhZmVmtmpZnammZ2Z2WQY8BUwGbgbSO3H8oILwswSzz0XO4nkucuA14G/Zi7DAS2/R1jN+rnn4JxzNO5JflcnqSd2967VPO7A2Um9fk067DDYaCO4+Wbo3Dl2GslX7v4rYThFqoZUpMG994bVBNRzT8rLi04SsdWpA+eeG0a2f/hh7DSSr8yslZk9YWYTzOyrskvsXLEtXQr33w8HHADNm1e/vRQPFagsnXZaWBb+5ptjJ5E8dj/h6GkpsBfwH+Ch6v6RmXU0s0mZWVd6VvD4zWY2LnP53MzmVPQ8afX88zB9euiQJFJeVgXKzM43s7UzHRruNbMPzGz/pMOlybrrwimnwKOPhp1JZCWs7u7DAXP3b9z9SuDAqv5BpqffnYSZV9oAXc2sTflt3P1Cd2/r7m2B24GnEkmfkLvvDgNzD6zyf0KKUbZHUKe4+0/A/kAD4ATgusRSpdR554XmiDvvjJ1E8tSizFIbX5jZOWZ2KNVPcdQBmOzuX7n7YuBRwiwslelK6B2YF0pL4YUX4OSTQ1O6SHnZFqiysRudgAfdfXy5+4rGZpvBwQeHFT4XLIidRvLQ+YR5+M4DtgeOB06q5t+syIwrLYCNgdcqe7JYs7JU5r77wsKgp54aO4mkUbYF6n0ze5lQoF4ys/pAUa43e+GFMGuWBu7Kisk01R3t7vPdvdTdT3b3wzPzUNaUY4An3L3SEXuxZmWpyLJloffevvvCJptEjSIplW2BOhXoCezg7r8AJcDJiaVKsT32gO23h3/9SwN3JXuZorHbSvzTFZlx5RjyqHnvlVfg22/VOUIql22B2hmY5O5zzOx44O/A3ORipZdZmMjyiy9g6NDYaSTPfGhmQ83sBDM7rOxSzb8ZA7Qys43NrC6hCP3hk2dmWxLOD4+s+djJ6NcPGjXS2EKpXLYF6t/AL2a2LdAD+JLQRbYoHX44tGwJN94YO4nkmXrALGBv4ODM5aCq/oG7LwXOAV4CJgKD3X28mfUxs0PKbXoM8GhmAHzqjR8Pzz4bZo7Qmk9SmWz7zSx1dzezzsAd7n6vmRXtac06dcK5qPPPh3ffDQsbilTH3VeqWdzdhxGmBit/X+/lbl+58sly75//DBPCnnNO7CSSZtkWqHlmdjmhe/numa6yJcnFSr9TToErr4QbboAhQ2KnkXxgZvcDfzjCcfdTIsSJ5ttv4ZFH4OyzoWHD2GkkzbJt4jsaWEQYD/Ud4UTtDYmlygNrrRVmXX7mGfj889hpJE88BzyfuQwH1gbmR00UwU03hZ8XXRQ3h6RfVgUqU5QeBtYxs4OAhe5etOegypx7LtSt+/sOJ1IVd3+y3OVh4CigqJZ6nzUrzBxx3HFhAmaRqmQ71dFRwGjgSMJONcrMjkgyWD7YYAM48UQYOBC++y52GslDrYD1Y4fIpTvugF9+gUu1yIhkIdsmvl6EMVAnufuJhOlX/i+5WPnjkktgyRJNIivVM7N5ZvZT2QV4lrBGVFH4+We47bbQrbxNm+q3F8m2QNVy9xnlbs9agX9b0Fq1gqOPDmM6fvwxdhpJM3ev7+5rl7ts7u5Pxs6VK488EvYRHT1JtrItMi+a2Utm1s3MuhFO8g6r5t8Ujb/9DebPD98ORSpjZoea2Trlbq9rZl1iZsqlJ54I81nuvHPsJJIvsu0kcQkwANgmcxng7kXTNFGdrbcOzRa33QY//RQ7jaTYFe7+2wws7j4HuCJinpz58Ud47bUwyN2KbpppWVlZN9Nleh5dlLlo5M9yevWC2bPh31rMWypX0f5WFItMDB0alqo5oui7VsmKqLJALX9St9xlXuYkb5WyWAl0IzN73cw+NLOPzazTqvwyMe2wA+y/f+hyrqU4pBJjzewmM9s0c7kJeD92qFx48klo0SJMtCySrSoLVAUndcsu9d197ar+bTYrgRImnR3s7u0Ic4n1W/lfJb5evWDGDLjnnthJJKXOBRYDjxEWHlwInB01UQ789BO8/DIcdpia92TFJNm88NtKoABmVrYS6IRy2zhhND3AOsC0BPMk7i9/gd13h+uuCwuwrbFG7ESSJu7+M2HZmqLy/POweHE4/ySyIpLsKp7NSqBXAsebWSmhV+C5FT1R2lYBrcrVV8O0aWFAokh5ZvaKma1b7nYDM3spZqZceOIJ2HBD9d6TFRd7LFNXYKC7NyOznHxmItr/kaZVQKuz++7QqRNce23oNCFSTqNMzz0A3H02BT6TxM8/wwsvhOa9WrH/2kjeSfIjk81KoKcCgwHcfSRhvZxGCWbKiWuugTlzwkznIuX8ama/zUBnZi2pYHbzQvLii6HTkJr3ZGUkWaCyWQn0W2AfADNrTShQ6W7Dy8K228Kxx8Itt8D06bHTSIr0At42swfN7CHgDeDyyJkS9eSTYdXc3XePnUTyUWIFKsuVQHsAp5vZR8AgoFu+rAhanT59whx9ffrETiJp4e4vEmYvn0T4vPcACnZQwsKF8Nxz0KVLWORTZEUl+rGpbiVQd58A7Jpkhlg23RTOOAP69w/r3rRqFTuRxGZmpwHnE5q7xwE7ASMJS8AXnCefhHnz4JhjYieRfKXTlgn6+99htdXg/zTvuwTnAzsA37j7XkA7YE7V/yR/DRgQ5t7ba6/YSSRfqUAl6E9/ggsvhMcegw8+iJ1GUmChuy8EMLPV3P0zYIvImRIxcSK8+Sacfrp678nK00cnYZdcAuutB5cX9KlwyVJpZhzU08ArZvYM8E3kTIm4+24oKYFu3WInkXymApWwddYJy3G8/HKYzVmKl7sf6u5z3P1KwoKf9wIFt9zGwoXwwANw6KGwfkGP8pKkqUDlwNlnQ/Pm0LMnFEYfRVlV7v6Guw9198Wxs9S0J58My2uccUbsJJLvVKByoF49+Mc/YMwYeOqp2GlEknXXXaFzxJ57xk4i+U4FKkdOPBHatAkzni9dGjuNSDImToS33oLu3dU5QladPkI5Urt2mEh20iS4997YaUSSMWBA6Bxx0kmxk0ghUIHKoc6dw5QvvXuHAYwihWTpUnjooTBzhDpHSE1QgcohM7jxxrCo4fXXx04jUrNGjIAffoCuXWMnkUKhApVjHTqEHfhf/4LS0thpRGrO4MGw1lpwwAGxk0ihUIGK4NprQ3fzXr1iJ5F8YGYdzWySmU02swpX5DWzo8xsgpmNN7NHcp1xyZLQQ7Vz59BrVaQmqEBF0KIFXHABPPigpkCSqplZbeBO4ACgDdDVzNost00rwrIdu7r7VsAFuc75+uswaxYcdVSuX1kKmQpUJJdfDg0bwsUXa/CuVKkDMNndv8oM6n0U6LzcNqcDd2ZW6MXdZ+Q4I489BmuvDfvvn+tXlkKmAhXJOuvAlVeGb57PPRc7jaRYU2BKudulmfvK2xzY3MzeMbP3zKxjztIBixfDkCFq3pOapwIVUffusOWW4ShqyZLYaSSP1QFaAXsCXYG7M5PS/oGZdTezsWY2dubMmlm8evhwmD1bzXtS81SgIiopCd3OP/88LGwoUoGpQPNyt5tl7iuvFBjq7kvc/b/A54SC9QfuPsDd27t7+8aNG9dIwMGDQ4vAfvvVyNOJ/EYFKrJOnWDffUNz3+zZsdNICo0BWpnZxmZWFzgGGLrcNk8Tjp4ws0aEJr+vchGurHmvS5ewOKdITVKBiswsjImaPRuuuip2Gkkbd18KnAO8BEwEBrv7eDPrY2aHZDZ7CZhlZhOA14FL3H1WLvK98grMnavmPUlGogUqH8ZvpME228App8Dtt8PkybHTSNq4+zB339zdN3X3qzP39Xb3oZnr7u4XuXsbd/+zuz+aq2xPPx2a9/bdN1evKMUksQKVL+M30qJvX6hbF84/X93OJT+4hyOovfcOn12RmpbkEVRejN9Iiw03DLOdDxsWlssWSbuvvoJvvg/0ByIAABFhSURBVIF99omdRApVkgWqxsZvJNE1No3OPTf0hLrwwtCzTyTNhg8PP9W8J0mJ3Ukiq/EbSXSNTaNatWDgwDDY8fjjNTZK0u3VV6FpU9h889hJpFAlWaBqdPxGsWjSJCyZPWZMOC8lkka//gqvvRaOnsxip5FClWSBSvX4jTQ74gjo1i2ck3r77dhpRP7oo4/C5LA6/yRJSqxApX38RtrdeitssgkceSRMXf64UySysvNPKlCSpDpJPrm7DwOGLXdf73LXHbgoc5Fy1l47jDHZaSc47DB44w1NxCnpMXw4tG4dmqRFkhK7k4RUYautwppRo0fDX/+q8VGSDosXw5tv6uhJkqcClXJdusAVV4TefXfcETuNCLz3Hvzyi7qXS/JUoPJA795hrZ0LL4Rx42KnkWL36qthSMQee8ROIoVOBSoPlI2PWm+9MJhXTX0S0/DhsMMOsG6FK06J1BwVqDyx7rpw7bWh2/kjRTmlrqTBTz/BqFE6/yS5oQKVR04+OXxzveQSmDcvdhopRu+8A8uWqUBJbqhA5ZFatcKSHNOna5YJiWPUqPA57NAhdhIpBipQeWbHHcOR1C23wKRJsdNIsRk9Ogx/WGut2EmkGKhA5aFrr4XVV4ezzoKlS2OnkWLhHgqUjp4kV1Sg8tAGG8BNN4XJOjWAV3Llv/8N8++pQEmuJDrVkSTn1FPDH4yrrw6LHfbpEzuRFLrRo8NPFSjJFRWoPNa3L3z3Xfi54YbhaEokKaNHh6blrbaKnUSKhQpUHjOD/v1hxgw4++xQpLp0iZ1KCtXo0bDddlBSEjuJFAudg8pzderAo4+G8VEnnwxTpsROJIVoyRL44AM170luqUAVgDXWgIcfDn9ETj45rHYqUpPGj4cFC8IXIZFcUYEqEJttBjffHOZJu/322Gmk0KiDhMSgAlVATjsNDjoILrssfOMVqSmjR4fJijfZJHYSKSYqUAXEDO65J6zGe/zxYWE5kZpQNkDXLHYSKSaJFigz62hmk8xsspn1rGK7w83Mzax9knmKwQYbhCI1bhyccorOR8mqmz8/HJGreU9yLbECZWa1gTuBA4A2QFcza1PBdvWB84FRSWUpNoccAlddFTpOnHeeZpqQVfPBB+GLjgqU5FqS46A6AJPd/SsAM3sU6AxMWG67vsD1wCUJZik6f/sbzJ4N//pXOHegmSZkZZV1kFAPPsm1JJv4mgLlR+WUZu77jZltBzR39+cTzFGUzOCGG8KUSH37hrn7RFbG6NHQsiWsv37sJFJsonWSMLNawE1Ajyy27W5mY81s7MyZM5MPVyDM4K674IgjoEeP0Oyn5r78U925XDPrZmYzzWxc5nJaTb6+ZjCXWJIsUFOB5uVuN8vcV6Y+sDUwwsy+BnYChlbUUcLdB7h7e3dv37hx4wQjF57atcO5qOOPh//7vzAl0rJlsVNJtrI9lws85u5tM5d7aur158+Hb76Btm1r6hlFspfkOagxQCsz25hQmI4Bji170N3nAo3KbpvZCOBidx+bYKaiVLcuPPAANGkC//xnmGD24YfDxJ+Setmey03EtGnhZ/PmVW8nkoTEjqDcfSlwDvASMBEY7O7jzayPmR2S1OtKxWrVguuvh1tvhaefhv32C2v7SOpVey4343Az+9jMnjCzSsvJijaXT820eTRpskKZRWpEoueg3H2Yu2/u7pu6+9WZ+3q7+9AKtt1TR0/JO+88eOwxGDsWdtkFvvwydiKpAc8CLd19G+AV4IHKNlzR5vKyAtW0opIokjDNJFGEjjwyzNn3ww+w884wSiPQ0qy6c7m4+yx3X5S5eQ+wfU29eFkTn46gJAYVqCK1664wciTUrw977QX3368efin127lcM6tLOJf7Py0QZrZhuZuHEJrUa8TUqeEzUr9+TT2jSPZUoIrY5puHItW+fZgWaY894NNPY6eS8rI8l3uemY03s4+A84BuNfX606apeU/iUYEqcuuvDyNGhPn7xo+Hdu3g0kth0aJq/6nkSHXnct39cnffyt23dfe93P2zmnrtqVPVvCfxqEAJtWqFGScmTYJu3cIMFCecoPFSEgqUjqAkliTHQUmeadQI7r4bWrcOM080aAD9+2uJhWL1668wfboKlMSjAiV/cNFFYYzUNdeEonX11bETSQw//ABLlqiJT+JRgZIKXXVV+AN1zTVhNvQe1c6YKIWmrIu5jqAkFhUoqZAZ9OsXluy4+OIwJ1vv3mruKyaaRUJiU4GSSpVNNLvWWnDllVBaCv/+N9TRp6YoaBYJiU1/aqRKJSVw773hW/TVV4eJZh99FNZcM3YySdq0aeGI+U9/ip1EipW6mUu1zMI5qX79YNgw2HFHeOed2KkkaVOnhnFyJSWxk0ixUoGSrP31r/D88zBvHuy2G5x+umZEL2SaRUJiU4GSFdKxY5hx4pJLwvx9W24Jt9wSOlFIYdEsEhKbCpSssLXWCgsffvghbL01XHghtGgROlL88EPsdFJTNIuExKYCJSvtz3+G11+Hd9+F3XeHf/wDNtooNP2NGxc7nayKRYvClw0VKIlJBUpW2c47h1V6x4+H444LXdPbtQtLegwaFGYjkPwyfXr4qSY+iUkFSmpMmzZhLr+pU+Hmm2HmTDj2WNhkk9AkOHt27ISSLY2BkjRQgZIa16ABXHABfPZZ6PW3xRZw2WXQvHlYymPOnNgJpTpaSVfSINECZWYdzWySmU02s54VPH6RmU0ws4/NbLiZtUgyj+RWrVrQqRO8+mo4J9WlC9x4I2y2Gdxxh5r+0kxHUJIGiRUoM6sN3AkcALQBuppZm+U2+xBo7+7bAE8A/0wqj8S17bbw0EPw/vvh+rnnhk4Wjz6qdafSaNo0WG21MFGwSCxJHkF1ACa7+1fuvhh4FOhcfgN3f93df8ncfA9olmAeSYF27cIR1bPPhrn+unYN564eeEBHVGlSNgZKkwNLTEkWqKbAlHK3SzP3VeZU4IWKHjCz7mY21szGzpw5swYjSgxmcNBB8Mkn8PjjsPrqYSXfzTYLA4BHjgyL5Uk8GgMlaZCKThJmdjzQHrihosfdfYC7t3f39o0bN85tOElMrVpwxBFhwO/QoeFI6tZbYZddoFkz6NULFi6MnbI4TZumDhISX5IFairQvNztZpn7/oeZ7Qv0Ag5x90UJ5pGUMoODD4YXXghd0x9+GDp0CIsltm8fCpjkjruOoCQdkixQY4BWZraxmdUFjgGGlt/AzNoBdxGK04wEs0ieWGedMHbq6adDwfrxxzB7+jXXwLffwuTJMGFC6MLuHjttYfrpJ/jlFxUoiS+xAuXuS4FzgJeAicBgdx9vZn3M7JDMZjcAawGPm9k4MxtaydNJEerYMZynOvTQ0NzXogW0agVbbQWtW4cOF4MGwdKlsZMWFq2kK2mR6IKF7j4MGLbcfb3LXd83ydeX/NewYeiKftppMGUK1K0b1ieaNQtuvz0cbfXqBWecAZtvHs5dNW0aFtmrlYozrPlHY6AkLbSirqSeGey33x/vP/PM0F39uuug53LDwBs3Dj0FDzkk/FutAJy9slkkVKAkNhUoyVu1akHnzuEycyaUlobLlCnw9tswZEhYs2q11WCHHULHiw4dwjmtFi00xqcyauKTtFCBkoLQuHG4tGsXbp91Vhj4+/bb8NxzYWzVnXfCTTeFxzfcMKwKvNtuoWC1bg1rrx0vf5pMmxbmU1x99dhJpNipQEnBKimBvfYKFwgF65NP4L334J13QvF6/PHft2/aNBSqgw+G886LkzkNtJKupIUKlBSNkhLYbrtwOeuscN+UKWF+wIkTf7989VXcnLGtvTZss03sFCIqUFLkmjcPly5dYidJjwceiJ1AJFBHXJE8UN3SNeW2O9zM3Mza5zKfSBJUoERSLsulazCz+sD5wKjcJhRJhgqUSPpVu3RNRl/gekBT7EpBUIESSb9ql64xs+2A5u7+fFVPpKVrJJ+oQInkOTOrBdwE9KhuWy1dI/lEBUok/apbuqY+sDUwwsy+BnYChqqjhOQ7FSiR9Kty6Rp3n+vujdy9pbu3BN4jLGEzNk5ckZqhAiWSclkuXSNScDRQVyQPVLd0zXL375mLTCJJM8+zZUnNbCbwTSUPNwJ+yGGcbKUxlzJlr3yuFu5eEL0L8nBfSmMmSGeufMhU7b6UdwWqKmY21t1Td2I4jbmUKXtpzZWkNP7OacwE6cxVKJl0DkpERFJJBUpERFKp0ArUgNgBKpHGXMqUvbTmSlIaf+c0ZoJ05iqITAV1DkpERApHoR1BiYhIgVCBEhGRVCqYApXtgm45yHGfmc0ws0/L3beemb1iZl9kfjbIYZ7mZva6mU0ws/Fmdn7sTJnXr2dmo83so0yuf2Tu39jMRmXex8cyU/vklJnVNrMPzey5tGTKpTTsS2nbjzKvn7p9qdD3o4IoUNku6JYjA4GOy93XExju7q2A4ZnbubIU6OHubQiTiJ6d+b+JmQlgEbC3u28LtAU6mtlOhPWMbnb3zYDZwKk5zgVh0b+J5W6nIVNOpGhfGki69iNI575U2PuRu+f9BdgZeKnc7cuByyPmaQl8Wu72JGDDzPUNgUkRsz0D7JeyTGsAHwA7Ekaa16nofc1RlmaEPzJ7A88BFjtTjn//1OxLad6PMhlStS8V4n5UEEdQZLGgW2QbuPv0zPXvgA1ihDCzlkA7wpLg0TNlmgDGATOAV4AvgTkeJkeFOO/jLcClwK+Z2w1TkCmX0rwvRf/MlknTvlTI+1GhFKi84eHrQ8779pvZWsCTwAXu/lMaMrn7MndvS/i21QHYMtcZyjOzg4AZ7v5+zBxSvVifWUjfvlTI+1GhzGZe3YJusX1vZhu6+3Qz25DwTSdnzKyEsEM97O5PpSFTee4+x8xeJxz2r2tmdTLftHL9Pu4KHGJmnYB6wNrArZEz5Vqa96Xon9k070uFuB8VyhFUlQu6pcBQ4KTM9ZMIbdc5YWYG3AtMdPeb0pApk6uxma2bub46oS1/IvA6cESMXO5+ubs387Do3zHAa+5+XMxMEaR5X4r9mU3dvlTw+1GMk3kJnZTrBHxOaH/tFTHHIGA6sITQznoqof11OPAF8CqwXg7z7EZocvgYGJe5dIqZKZNrG+DDTK5Pgd6Z+zcBRgOTgceB1SK9j3sCz6UpUw5/9+j7Utr2o0ym1O1Lhb4faaojERFJpUJp4hMRkQKjAiUiIqmkAiUiIqmkAiUiIqmkAiUiIqmkAiUAmNmeZbMOi8jK0X5Us1SgREQklVSg8oyZHZ9Z/2Wcmd2VmShyvpndnFkPZriZNc5s29bM3jOzj81sSNk6NWa2mZm9mllD5gMz2zTz9GuZ2RNm9pmZPZwZOY+ZXZdZA+djM7sx0q8uUmO0H+WJGKOLdVnpUdmtgWeBksztfsCJhNHtx2Xu6w3ckbn+MbBH5nof4JbM9VHAoZnr9QjT9O8JzCXMkVULGEkYOd+QsJxA2aDudWP/P+iiy6pctB/lz0VHUPllH2B7YExmev19CNOH/Ao8ltnmIWA3M1uHsBO8kbn/AeAvZlYfaOruQwDcfaG7/5LZZrS7l7r7r4RpXFoSdraFwL1mdhhQtq1IvtJ+lCdUoPKLAQ+4e9vMZQt3v7KC7VZ2/qpF5a4vIywutpQwhf8TwEHAiyv53CJpof0oT6hA5ZfhwBFmtj6Ama1nZi0I72PZLMHHAm+7+1xgtpntnrn/BOANd58HlJpZl8xzrGZma1T2gpm1b9Zx92HAhcC2SfxiIjmk/ShPFMp6UEXB3SeY2d+Bl82sFmGm57OBn4EOmcdmAEdn/slJQP/MjvMVcHLm/hOAu8ysT+Y5jqziZesDz5hZPcI3z4tq+NcSySntR/lDs5kXADOb7+5rxc4hks+0H6WPmvhERCSVdAQlIiKppCMoERFJJRUoERFJJRUoERFJJRUoERFJJRUoERFJpf8P69praHRnBaIAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxqPsFm8Ami-"
      },
      "source": [
        "It seems those final epochs were a little bit oscillating, but our overall performance is great already. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG-ZH_GrBBB9"
      },
      "source": [
        "###Learning rate schedulers\n",
        "From the learning curves above, we can guess the optimizer might be wandering around the global minimum. We could improve a little bit more if we use some learning rate scheduler. For that, we have to change our training function. Notice that now we pass a `scheduler` to our new function. In the body of the function, it is enough to add a `scheduler.step()` call in the suitable position, just after processing a complete epoch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tivLC3HrBTup"
      },
      "source": [
        "def train_loop_scheduler(dataloader, model, loss_fn, optimizer, scheduler, device):        \n",
        "    model.train()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "      #X = F.interpolate(X, size=32)\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "      # Compute prediction and loss\n",
        "      pred = model(X)\n",
        "      loss = loss_fn(pred, y)\n",
        "        \n",
        "      # Backpropagation\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Store loss and accuracy\n",
        "      train_loss += loss.item()\n",
        "      train_acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "      if batch % 100 == 0:\n",
        "        loss, current = loss.item(), batch * len(X)\n",
        "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "      \n",
        "    scheduler.step() # Calculate the new learning rate for the next epoch\n",
        "    train_loss /= num_batches\n",
        "    train_acc /= size\n",
        "    return train_loss, train_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPZCjchICBRV"
      },
      "source": [
        "Now we can use any scheduler from the [long list of Pytorch](https://pytorch.org/docs/stable/optim.html). For this example, we will use the cosine scheduler. \n",
        "\n",
        "**EXERCISE:** write the code to use a cosine scheduler with our new function `train_loop_scheduler()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z7ZBafoCKrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "500ea36d-302a-477c-c54b-5d045704ee48"
      },
      "source": [
        "import time\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size = 64\n",
        "epochs = 40\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(0)\n",
        "\n",
        "model = MyMLPBN()\n",
        "model = model.to(device)\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
        "\n",
        "train_losses, train_accuracies  = [], []\n",
        "start = time.time()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    # call to the new training function with the scheduler and store the returned values\n",
        "    train_loss, train_acc = train_loop_scheduler(train_dataloader, model, loss_fn, optimizer, scheduler, device)\n",
        "\n",
        "    print(f'train loss: {train_loss}, train_acc: {train_acc}')\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)    \n",
        "end = time.time()\n",
        "print(\"Done!\")\n",
        "print(f'Training time: {end-start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.817509  [    0/40000]\n",
            "loss: 1.810218  [ 6400/40000]\n",
            "loss: 1.538449  [12800/40000]\n",
            "loss: 1.541885  [19200/40000]\n",
            "loss: 1.408666  [25600/40000]\n",
            "loss: 1.488074  [32000/40000]\n",
            "loss: 1.639456  [38400/40000]\n",
            "train loss: 1.6729518020629883, train_acc: 0.4125\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.552140  [    0/40000]\n",
            "loss: 1.352982  [ 6400/40000]\n",
            "loss: 1.302377  [12800/40000]\n",
            "loss: 1.624085  [19200/40000]\n",
            "loss: 1.307402  [25600/40000]\n",
            "loss: 1.286090  [32000/40000]\n",
            "loss: 1.280512  [38400/40000]\n",
            "train loss: 1.4098610116958619, train_acc: 0.5057\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.369732  [    0/40000]\n",
            "loss: 1.266218  [ 6400/40000]\n",
            "loss: 1.358200  [12800/40000]\n",
            "loss: 1.340324  [19200/40000]\n",
            "loss: 1.203812  [25600/40000]\n",
            "loss: 1.311342  [32000/40000]\n",
            "loss: 1.259836  [38400/40000]\n",
            "train loss: 1.2892048563957215, train_acc: 0.551925\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.153481  [    0/40000]\n",
            "loss: 1.304113  [ 6400/40000]\n",
            "loss: 1.035591  [12800/40000]\n",
            "loss: 1.164127  [19200/40000]\n",
            "loss: 1.200414  [25600/40000]\n",
            "loss: 1.431027  [32000/40000]\n",
            "loss: 1.227269  [38400/40000]\n",
            "train loss: 1.1971977422714233, train_acc: 0.586575\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.091229  [    0/40000]\n",
            "loss: 0.981951  [ 6400/40000]\n",
            "loss: 1.270730  [12800/40000]\n",
            "loss: 1.089046  [19200/40000]\n",
            "loss: 1.269428  [25600/40000]\n",
            "loss: 1.347144  [32000/40000]\n",
            "loss: 1.095086  [38400/40000]\n",
            "train loss: 1.1188254658699035, train_acc: 0.617225\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.182549  [    0/40000]\n",
            "loss: 1.013744  [ 6400/40000]\n",
            "loss: 0.737952  [12800/40000]\n",
            "loss: 1.108097  [19200/40000]\n",
            "loss: 0.968544  [25600/40000]\n",
            "loss: 0.878268  [32000/40000]\n",
            "loss: 0.775209  [38400/40000]\n",
            "train loss: 1.047061118221283, train_acc: 0.643175\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.035881  [    0/40000]\n",
            "loss: 1.081120  [ 6400/40000]\n",
            "loss: 1.031069  [12800/40000]\n",
            "loss: 0.820546  [19200/40000]\n",
            "loss: 1.167247  [25600/40000]\n",
            "loss: 1.275901  [32000/40000]\n",
            "loss: 1.012835  [38400/40000]\n",
            "train loss: 0.9771879063606262, train_acc: 0.671375\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.090208  [    0/40000]\n",
            "loss: 0.945629  [ 6400/40000]\n",
            "loss: 0.917244  [12800/40000]\n",
            "loss: 0.861775  [19200/40000]\n",
            "loss: 0.981772  [25600/40000]\n",
            "loss: 0.834215  [32000/40000]\n",
            "loss: 0.887957  [38400/40000]\n",
            "train loss: 0.913648784160614, train_acc: 0.695725\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.771910  [    0/40000]\n",
            "loss: 0.972770  [ 6400/40000]\n",
            "loss: 0.722234  [12800/40000]\n",
            "loss: 0.817628  [19200/40000]\n",
            "loss: 0.872069  [25600/40000]\n",
            "loss: 0.901209  [32000/40000]\n",
            "loss: 1.073412  [38400/40000]\n",
            "train loss: 0.8552446231842041, train_acc: 0.71625\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.741029  [    0/40000]\n",
            "loss: 0.811289  [ 6400/40000]\n",
            "loss: 0.743475  [12800/40000]\n",
            "loss: 0.737125  [19200/40000]\n",
            "loss: 0.828542  [25600/40000]\n",
            "loss: 0.709066  [32000/40000]\n",
            "loss: 0.872209  [38400/40000]\n",
            "train loss: 0.7958127993106842, train_acc: 0.740075\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.633286  [    0/40000]\n",
            "loss: 0.779174  [ 6400/40000]\n",
            "loss: 0.583901  [12800/40000]\n",
            "loss: 0.755862  [19200/40000]\n",
            "loss: 0.813509  [25600/40000]\n",
            "loss: 0.876887  [32000/40000]\n",
            "loss: 0.991599  [38400/40000]\n",
            "train loss: 0.7433555322170258, train_acc: 0.75895\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.788208  [    0/40000]\n",
            "loss: 0.557623  [ 6400/40000]\n",
            "loss: 0.825484  [12800/40000]\n",
            "loss: 0.609911  [19200/40000]\n",
            "loss: 0.849055  [25600/40000]\n",
            "loss: 0.791486  [32000/40000]\n",
            "loss: 0.805440  [38400/40000]\n",
            "train loss: 0.6890441546916962, train_acc: 0.782425\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.493499  [    0/40000]\n",
            "loss: 0.636963  [ 6400/40000]\n",
            "loss: 0.626846  [12800/40000]\n",
            "loss: 0.730062  [19200/40000]\n",
            "loss: 0.747982  [25600/40000]\n",
            "loss: 0.772349  [32000/40000]\n",
            "loss: 0.725766  [38400/40000]\n",
            "train loss: 0.639769399213791, train_acc: 0.7996\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.577621  [    0/40000]\n",
            "loss: 0.544797  [ 6400/40000]\n",
            "loss: 0.580820  [12800/40000]\n",
            "loss: 0.595341  [19200/40000]\n",
            "loss: 0.673267  [25600/40000]\n",
            "loss: 0.643823  [32000/40000]\n",
            "loss: 0.575836  [38400/40000]\n",
            "train loss: 0.5911845428943634, train_acc: 0.818525\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.554123  [    0/40000]\n",
            "loss: 0.469550  [ 6400/40000]\n",
            "loss: 0.557861  [12800/40000]\n",
            "loss: 0.468122  [19200/40000]\n",
            "loss: 0.532599  [25600/40000]\n",
            "loss: 0.638500  [32000/40000]\n",
            "loss: 0.540014  [38400/40000]\n",
            "train loss: 0.5495938069343567, train_acc: 0.833375\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.482737  [    0/40000]\n",
            "loss: 0.518812  [ 6400/40000]\n",
            "loss: 0.605898  [12800/40000]\n",
            "loss: 0.632181  [19200/40000]\n",
            "loss: 0.721691  [25600/40000]\n",
            "loss: 0.578973  [32000/40000]\n",
            "loss: 0.519131  [38400/40000]\n",
            "train loss: 0.5101167347431182, train_acc: 0.849425\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.528267  [    0/40000]\n",
            "loss: 0.455410  [ 6400/40000]\n",
            "loss: 0.370360  [12800/40000]\n",
            "loss: 0.490417  [19200/40000]\n",
            "loss: 0.502703  [25600/40000]\n",
            "loss: 0.513081  [32000/40000]\n",
            "loss: 0.475161  [38400/40000]\n",
            "train loss: 0.468750342130661, train_acc: 0.864525\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.346642  [    0/40000]\n",
            "loss: 0.457879  [ 6400/40000]\n",
            "loss: 0.516666  [12800/40000]\n",
            "loss: 0.474547  [19200/40000]\n",
            "loss: 0.357128  [25600/40000]\n",
            "loss: 0.375624  [32000/40000]\n",
            "loss: 0.402772  [38400/40000]\n",
            "train loss: 0.4337944585800171, train_acc: 0.876975\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.328456  [    0/40000]\n",
            "loss: 0.400149  [ 6400/40000]\n",
            "loss: 0.421457  [12800/40000]\n",
            "loss: 0.321298  [19200/40000]\n",
            "loss: 0.527634  [25600/40000]\n",
            "loss: 0.310241  [32000/40000]\n",
            "loss: 0.370212  [38400/40000]\n",
            "train loss: 0.3968077923297882, train_acc: 0.890875\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.386263  [    0/40000]\n",
            "loss: 0.413100  [ 6400/40000]\n",
            "loss: 0.308560  [12800/40000]\n",
            "loss: 0.317433  [19200/40000]\n",
            "loss: 0.346062  [25600/40000]\n",
            "loss: 0.313895  [32000/40000]\n",
            "loss: 0.275382  [38400/40000]\n",
            "train loss: 0.36476953811645507, train_acc: 0.901475\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.414642  [    0/40000]\n",
            "loss: 0.333973  [ 6400/40000]\n",
            "loss: 0.288472  [12800/40000]\n",
            "loss: 0.370601  [19200/40000]\n",
            "loss: 0.394204  [25600/40000]\n",
            "loss: 0.360556  [32000/40000]\n",
            "loss: 0.381437  [38400/40000]\n",
            "train loss: 0.3405202839612961, train_acc: 0.9107\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.342589  [    0/40000]\n",
            "loss: 0.255842  [ 6400/40000]\n",
            "loss: 0.242366  [12800/40000]\n",
            "loss: 0.352517  [19200/40000]\n",
            "loss: 0.226028  [25600/40000]\n",
            "loss: 0.326725  [32000/40000]\n",
            "loss: 0.337408  [38400/40000]\n",
            "train loss: 0.3137102722644806, train_acc: 0.9216\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.197666  [    0/40000]\n",
            "loss: 0.203815  [ 6400/40000]\n",
            "loss: 0.395810  [12800/40000]\n",
            "loss: 0.358705  [19200/40000]\n",
            "loss: 0.237022  [25600/40000]\n",
            "loss: 0.324814  [32000/40000]\n",
            "loss: 0.372459  [38400/40000]\n",
            "train loss: 0.2907500694155693, train_acc: 0.92975\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.209400  [    0/40000]\n",
            "loss: 0.304307  [ 6400/40000]\n",
            "loss: 0.335142  [12800/40000]\n",
            "loss: 0.343384  [19200/40000]\n",
            "loss: 0.189517  [25600/40000]\n",
            "loss: 0.375164  [32000/40000]\n",
            "loss: 0.292940  [38400/40000]\n",
            "train loss: 0.2664328665971756, train_acc: 0.9388\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.305658  [    0/40000]\n",
            "loss: 0.231374  [ 6400/40000]\n",
            "loss: 0.197414  [12800/40000]\n",
            "loss: 0.260551  [19200/40000]\n",
            "loss: 0.303087  [25600/40000]\n",
            "loss: 0.227500  [32000/40000]\n",
            "loss: 0.221914  [38400/40000]\n",
            "train loss: 0.24600950255393983, train_acc: 0.946\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.196381  [    0/40000]\n",
            "loss: 0.190580  [ 6400/40000]\n",
            "loss: 0.176846  [12800/40000]\n",
            "loss: 0.245530  [19200/40000]\n",
            "loss: 0.219802  [25600/40000]\n",
            "loss: 0.267988  [32000/40000]\n",
            "loss: 0.223724  [38400/40000]\n",
            "train loss: 0.22731481636762618, train_acc: 0.95195\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.181384  [    0/40000]\n",
            "loss: 0.232486  [ 6400/40000]\n",
            "loss: 0.181809  [12800/40000]\n",
            "loss: 0.182951  [19200/40000]\n",
            "loss: 0.269299  [25600/40000]\n",
            "loss: 0.160295  [32000/40000]\n",
            "loss: 0.205579  [38400/40000]\n",
            "train loss: 0.21325574027299882, train_acc: 0.9554\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.168220  [    0/40000]\n",
            "loss: 0.194471  [ 6400/40000]\n",
            "loss: 0.138166  [12800/40000]\n",
            "loss: 0.195087  [19200/40000]\n",
            "loss: 0.184158  [25600/40000]\n",
            "loss: 0.206923  [32000/40000]\n",
            "loss: 0.115968  [38400/40000]\n",
            "train loss: 0.19845284601449967, train_acc: 0.9622\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.202819  [    0/40000]\n",
            "loss: 0.140225  [ 6400/40000]\n",
            "loss: 0.193927  [12800/40000]\n",
            "loss: 0.151624  [19200/40000]\n",
            "loss: 0.238210  [25600/40000]\n",
            "loss: 0.196287  [32000/40000]\n",
            "loss: 0.192167  [38400/40000]\n",
            "train loss: 0.18737167012691497, train_acc: 0.9654\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.141659  [    0/40000]\n",
            "loss: 0.151584  [ 6400/40000]\n",
            "loss: 0.179111  [12800/40000]\n",
            "loss: 0.185818  [19200/40000]\n",
            "loss: 0.152211  [25600/40000]\n",
            "loss: 0.177968  [32000/40000]\n",
            "loss: 0.223293  [38400/40000]\n",
            "train loss: 0.17501965817213058, train_acc: 0.96965\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.162447  [    0/40000]\n",
            "loss: 0.115363  [ 6400/40000]\n",
            "loss: 0.145642  [12800/40000]\n",
            "loss: 0.135435  [19200/40000]\n",
            "loss: 0.123545  [25600/40000]\n",
            "loss: 0.173988  [32000/40000]\n",
            "loss: 0.188577  [38400/40000]\n",
            "train loss: 0.16769668651819228, train_acc: 0.972425\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.127286  [    0/40000]\n",
            "loss: 0.202260  [ 6400/40000]\n",
            "loss: 0.175321  [12800/40000]\n",
            "loss: 0.226528  [19200/40000]\n",
            "loss: 0.282280  [25600/40000]\n",
            "loss: 0.182926  [32000/40000]\n",
            "loss: 0.170575  [38400/40000]\n",
            "train loss: 0.15912407307624818, train_acc: 0.9748\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.153261  [    0/40000]\n",
            "loss: 0.124888  [ 6400/40000]\n",
            "loss: 0.118857  [12800/40000]\n",
            "loss: 0.200803  [19200/40000]\n",
            "loss: 0.165319  [25600/40000]\n",
            "loss: 0.109687  [32000/40000]\n",
            "loss: 0.142964  [38400/40000]\n",
            "train loss: 0.15103233855962753, train_acc: 0.97755\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.112934  [    0/40000]\n",
            "loss: 0.105799  [ 6400/40000]\n",
            "loss: 0.162232  [12800/40000]\n",
            "loss: 0.138387  [19200/40000]\n",
            "loss: 0.150810  [25600/40000]\n",
            "loss: 0.144455  [32000/40000]\n",
            "loss: 0.131614  [38400/40000]\n",
            "train loss: 0.14561316459178925, train_acc: 0.978825\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.168533  [    0/40000]\n",
            "loss: 0.150970  [ 6400/40000]\n",
            "loss: 0.172049  [12800/40000]\n",
            "loss: 0.110048  [19200/40000]\n",
            "loss: 0.156270  [25600/40000]\n",
            "loss: 0.109338  [32000/40000]\n",
            "loss: 0.154068  [38400/40000]\n",
            "train loss: 0.14112385162115096, train_acc: 0.98005\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.205677  [    0/40000]\n",
            "loss: 0.120497  [ 6400/40000]\n",
            "loss: 0.099927  [12800/40000]\n",
            "loss: 0.122369  [19200/40000]\n",
            "loss: 0.257480  [25600/40000]\n",
            "loss: 0.113416  [32000/40000]\n",
            "loss: 0.138607  [38400/40000]\n",
            "train loss: 0.13729651831388473, train_acc: 0.98085\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.131690  [    0/40000]\n",
            "loss: 0.136926  [ 6400/40000]\n",
            "loss: 0.208481  [12800/40000]\n",
            "loss: 0.127197  [19200/40000]\n",
            "loss: 0.127797  [25600/40000]\n",
            "loss: 0.161923  [32000/40000]\n",
            "loss: 0.144295  [38400/40000]\n",
            "train loss: 0.13447842067480087, train_acc: 0.982725\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.170697  [    0/40000]\n",
            "loss: 0.141495  [ 6400/40000]\n",
            "loss: 0.097700  [12800/40000]\n",
            "loss: 0.109640  [19200/40000]\n",
            "loss: 0.094667  [25600/40000]\n",
            "loss: 0.115168  [32000/40000]\n",
            "loss: 0.147581  [38400/40000]\n",
            "train loss: 0.130912846326828, train_acc: 0.9836\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.106221  [    0/40000]\n",
            "loss: 0.213832  [ 6400/40000]\n",
            "loss: 0.137904  [12800/40000]\n",
            "loss: 0.141178  [19200/40000]\n",
            "loss: 0.110618  [25600/40000]\n",
            "loss: 0.177640  [32000/40000]\n",
            "loss: 0.150360  [38400/40000]\n",
            "train loss: 0.131455633187294, train_acc: 0.9834\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.151486  [    0/40000]\n",
            "loss: 0.163455  [ 6400/40000]\n",
            "loss: 0.182810  [12800/40000]\n",
            "loss: 0.125275  [19200/40000]\n",
            "loss: 0.177528  [25600/40000]\n",
            "loss: 0.108773  [32000/40000]\n",
            "loss: 0.108751  [38400/40000]\n",
            "train loss: 0.13201260585784913, train_acc: 0.982775\n",
            "Done!\n",
            "Training time: 243.01827597618103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR0I_HJwEWx2"
      },
      "source": [
        "The train accuracy improved further with a best value of 0.983. Let's look at the training curves:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Gh-okj-EZSP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "9c979a82-3870-48b8-a472-3ddb692231f1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(epochs), train_losses, color='blue', label='train')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(epochs), train_accuracies, color='blue', label='train')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiPQhF8QF3Qc"
      },
      "source": [
        "We will stop here, as we already have a very good training regime. To sum up, this is our current configuration:\n",
        "\n",
        "\n",
        "*   Data preprocessing: scale pixel values between 0 and 1 (we did not explore this).\n",
        "*   Weight initialization: He.\n",
        "*   Batch normalization: yes.\n",
        "*   Batch size: 64 (we did not explore this hyperparameter).\n",
        "*   Learning rate (initial): 1e-4.\n",
        "*   Epochs: 40.\n",
        "*   Optimizer: Adam.\n",
        "*   Scheduler: Cosine (we did not test other schedulers).\n",
        "\n",
        "Our best training accuracy is 0.98.\n",
        "\n",
        "Let's save our best trained model in the disk, just in case.\n",
        "\n",
        "**EXERCISE:** write the code to save the trained model under the name of *model.pth*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6mbnoEyILcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c3331e-0e15-4390-ac0f-a23a110a16ae"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "model_save_name = 'model.pth'\n",
        "path = F\"/content/gdrive/MyDrive/{model_save_name}\"\n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAY4OBGvGqt1"
      },
      "source": [
        "##Improve your test error\n",
        "Although our training accuracy is very good and we should be satisfied, the most important performance metric is accuracy for new, unseen samples. We will estimate such performance using our development set. \n",
        "\n",
        "**EXERCISE:** write the code to load the previously saved Pytorch model called *model.pth* into the `model` variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8y_Kpq5Npjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48e8b16c-17c6-4d9a-bc5a-ae255ac0bd5d"
      },
      "source": [
        "model.load_state_dict(torch.load(path))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37dx8nE6DTFe"
      },
      "source": [
        "**EXERCISE:** write the code to create `dev_dataloader` from `dev_set`. Do not shuffle the data for development, as it is only to check the performance. Write also de code to call to `test_loop` and obtain `dev_loss` and `dev_acc`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ1fUFIuNvrJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "117e2f35-862c-494a-de44-e2871249d728"
      },
      "source": [
        "dev_dataloader = DataLoader(dev_set,batch_size)\n",
        "dev_loss, dev_acc = test_loop(dev_dataloader, model, loss_fn, device)\n",
        "\"\"\"\n",
        "def test_loop(dataloader, model, loss_fn, device):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "          X = X.to(device)\n",
        "          y = y.to(device)\n",
        "          pred = model(X)\n",
        "          test_loss += loss_fn(pred, y).item()\n",
        "          test_acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            \n",
        "    test_loss /= num_batches\n",
        "    test_acc /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*test_acc):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss, test_acc\"\"\"\n",
        "########################\n",
        "\n",
        "print(f'dev loss: {dev_loss}, dev accuracy: {dev_acc}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 54.2%, Avg loss: 1.648208 \n",
            "\n",
            "dev loss: 1.6482075832451983, dev accuracy: 0.5416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgaESpfGPPZy"
      },
      "source": [
        "Our model is clearly overfitting! It obtains 0.54 accuracy for new data, when training accuracy was 0.98. We need some regularization here. But first of all, we have to check learning curves also for development data, to have a better diagnose. To reduce training time, we will only train for 20 epochs, as it is enough to have a clear idea of what is going on:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R63AaqbuQeW0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b32924c-46df-430e-e0cf-9101aff5398b"
      },
      "source": [
        "import time\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(0)\n",
        "\n",
        "model = MyMLPBN()\n",
        "model = model.to(device)\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "dev_dataloader = DataLoader(dev_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "train_losses, train_accuracies, dev_accuracies, dev_losses  = [], [], [], []\n",
        "start = time.time()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss, train_acc = train_loop_scheduler(train_dataloader, model, loss_fn, optimizer, scheduler, device)\n",
        "    print(f'train loss: {train_loss}, train_acc: {train_acc}')\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    dev_loss, dev_acc = test_loop(dev_dataloader, model, loss_fn, device)\n",
        "    dev_losses.append(dev_loss)\n",
        "    dev_accuracies.append(dev_acc)    \n",
        "end = time.time()\n",
        "print(\"Done!\")\n",
        "print(f'Best dev accuracy: {max(dev_accuracies)} in epoch {dev_accuracies.index(max(dev_accuracies))+1}')\n",
        "print(f'Training time: {end-start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.817509  [    0/40000]\n",
            "loss: 1.810218  [ 6400/40000]\n",
            "loss: 1.538449  [12800/40000]\n",
            "loss: 1.541885  [19200/40000]\n",
            "loss: 1.408666  [25600/40000]\n",
            "loss: 1.488074  [32000/40000]\n",
            "loss: 1.639456  [38400/40000]\n",
            "train loss: 1.6729518020629883, train_acc: 0.4125\n",
            "Test Error: \n",
            " Accuracy: 46.1%, Avg loss: 1.546681 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.523000  [    0/40000]\n",
            "loss: 1.816629  [ 6400/40000]\n",
            "loss: 1.473076  [12800/40000]\n",
            "loss: 1.500469  [19200/40000]\n",
            "loss: 1.328741  [25600/40000]\n",
            "loss: 1.523757  [32000/40000]\n",
            "loss: 1.345215  [38400/40000]\n",
            "train loss: 1.4091113867759704, train_acc: 0.506725\n",
            "Test Error: \n",
            " Accuracy: 48.9%, Avg loss: 1.467902 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.331209  [    0/40000]\n",
            "loss: 1.411134  [ 6400/40000]\n",
            "loss: 1.184598  [12800/40000]\n",
            "loss: 1.297385  [19200/40000]\n",
            "loss: 1.269835  [25600/40000]\n",
            "loss: 1.475968  [32000/40000]\n",
            "loss: 1.304483  [38400/40000]\n",
            "train loss: 1.288541773891449, train_acc: 0.5528\n",
            "Test Error: \n",
            " Accuracy: 49.1%, Avg loss: 1.451494 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.214763  [    0/40000]\n",
            "loss: 1.084800  [ 6400/40000]\n",
            "loss: 1.334317  [12800/40000]\n",
            "loss: 1.209212  [19200/40000]\n",
            "loss: 1.172113  [25600/40000]\n",
            "loss: 1.072075  [32000/40000]\n",
            "loss: 1.236855  [38400/40000]\n",
            "train loss: 1.1945486135482788, train_acc: 0.58805\n",
            "Test Error: \n",
            " Accuracy: 50.2%, Avg loss: 1.423485 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.121506  [    0/40000]\n",
            "loss: 1.246459  [ 6400/40000]\n",
            "loss: 1.167043  [12800/40000]\n",
            "loss: 0.970775  [19200/40000]\n",
            "loss: 1.325508  [25600/40000]\n",
            "loss: 1.522551  [32000/40000]\n",
            "loss: 1.098764  [38400/40000]\n",
            "train loss: 1.1133528510093689, train_acc: 0.619075\n",
            "Test Error: \n",
            " Accuracy: 51.5%, Avg loss: 1.397188 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.040627  [    0/40000]\n",
            "loss: 1.129180  [ 6400/40000]\n",
            "loss: 0.892339  [12800/40000]\n",
            "loss: 1.221351  [19200/40000]\n",
            "loss: 1.084559  [25600/40000]\n",
            "loss: 1.031013  [32000/40000]\n",
            "loss: 1.218766  [38400/40000]\n",
            "train loss: 1.0378990159988404, train_acc: 0.648125\n",
            "Test Error: \n",
            " Accuracy: 48.2%, Avg loss: 1.472820 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.887385  [    0/40000]\n",
            "loss: 1.067488  [ 6400/40000]\n",
            "loss: 0.936511  [12800/40000]\n",
            "loss: 0.953050  [19200/40000]\n",
            "loss: 0.976637  [25600/40000]\n",
            "loss: 0.869571  [32000/40000]\n",
            "loss: 1.013722  [38400/40000]\n",
            "train loss: 0.9667457139968872, train_acc: 0.678725\n",
            "Test Error: \n",
            " Accuracy: 49.2%, Avg loss: 1.468529 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.942140  [    0/40000]\n",
            "loss: 0.758919  [ 6400/40000]\n",
            "loss: 0.805391  [12800/40000]\n",
            "loss: 0.866642  [19200/40000]\n",
            "loss: 0.912000  [25600/40000]\n",
            "loss: 0.926772  [32000/40000]\n",
            "loss: 0.955029  [38400/40000]\n",
            "train loss: 0.9037611788749694, train_acc: 0.7017\n",
            "Test Error: \n",
            " Accuracy: 50.9%, Avg loss: 1.389849 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.667862  [    0/40000]\n",
            "loss: 0.802104  [ 6400/40000]\n",
            "loss: 0.789556  [12800/40000]\n",
            "loss: 0.915203  [19200/40000]\n",
            "loss: 0.868981  [25600/40000]\n",
            "loss: 0.982550  [32000/40000]\n",
            "loss: 0.901272  [38400/40000]\n",
            "train loss: 0.8381934819221497, train_acc: 0.72735\n",
            "Test Error: \n",
            " Accuracy: 51.1%, Avg loss: 1.429157 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.638966  [    0/40000]\n",
            "loss: 0.784662  [ 6400/40000]\n",
            "loss: 0.735874  [12800/40000]\n",
            "loss: 0.976500  [19200/40000]\n",
            "loss: 0.770183  [25600/40000]\n",
            "loss: 0.795639  [32000/40000]\n",
            "loss: 0.716991  [38400/40000]\n",
            "train loss: 0.7844936175346374, train_acc: 0.749425\n",
            "Test Error: \n",
            " Accuracy: 52.0%, Avg loss: 1.423092 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.638004  [    0/40000]\n",
            "loss: 0.760795  [ 6400/40000]\n",
            "loss: 0.708007  [12800/40000]\n",
            "loss: 0.863556  [19200/40000]\n",
            "loss: 0.953749  [25600/40000]\n",
            "loss: 0.708795  [32000/40000]\n",
            "loss: 0.728794  [38400/40000]\n",
            "train loss: 0.729024598312378, train_acc: 0.769475\n",
            "Test Error: \n",
            " Accuracy: 53.3%, Avg loss: 1.361003 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.652430  [    0/40000]\n",
            "loss: 0.637341  [ 6400/40000]\n",
            "loss: 0.703072  [12800/40000]\n",
            "loss: 0.678942  [19200/40000]\n",
            "loss: 0.679336  [25600/40000]\n",
            "loss: 0.705615  [32000/40000]\n",
            "loss: 0.576259  [38400/40000]\n",
            "train loss: 0.6759276713848114, train_acc: 0.793325\n",
            "Test Error: \n",
            " Accuracy: 51.5%, Avg loss: 1.446223 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.530882  [    0/40000]\n",
            "loss: 0.660423  [ 6400/40000]\n",
            "loss: 0.639806  [12800/40000]\n",
            "loss: 0.606581  [19200/40000]\n",
            "loss: 0.754793  [25600/40000]\n",
            "loss: 0.550859  [32000/40000]\n",
            "loss: 0.580126  [38400/40000]\n",
            "train loss: 0.6307289776802063, train_acc: 0.813625\n",
            "Test Error: \n",
            " Accuracy: 52.0%, Avg loss: 1.405335 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.707980  [    0/40000]\n",
            "loss: 0.771883  [ 6400/40000]\n",
            "loss: 0.574363  [12800/40000]\n",
            "loss: 0.580418  [19200/40000]\n",
            "loss: 0.693215  [25600/40000]\n",
            "loss: 0.582273  [32000/40000]\n",
            "loss: 0.593465  [38400/40000]\n",
            "train loss: 0.5942318902492523, train_acc: 0.828675\n",
            "Test Error: \n",
            " Accuracy: 53.3%, Avg loss: 1.373648 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.586537  [    0/40000]\n",
            "loss: 0.502930  [ 6400/40000]\n",
            "loss: 0.539188  [12800/40000]\n",
            "loss: 0.611135  [19200/40000]\n",
            "loss: 0.482172  [25600/40000]\n",
            "loss: 0.584574  [32000/40000]\n",
            "loss: 0.598499  [38400/40000]\n",
            "train loss: 0.5630480802536011, train_acc: 0.842525\n",
            "Test Error: \n",
            " Accuracy: 54.1%, Avg loss: 1.353190 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.587442  [    0/40000]\n",
            "loss: 0.436357  [ 6400/40000]\n",
            "loss: 0.674752  [12800/40000]\n",
            "loss: 0.542472  [19200/40000]\n",
            "loss: 0.460945  [25600/40000]\n",
            "loss: 0.563254  [32000/40000]\n",
            "loss: 0.441419  [38400/40000]\n",
            "train loss: 0.5359328997135162, train_acc: 0.855075\n",
            "Test Error: \n",
            " Accuracy: 54.6%, Avg loss: 1.355445 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.654246  [    0/40000]\n",
            "loss: 0.543988  [ 6400/40000]\n",
            "loss: 0.474295  [12800/40000]\n",
            "loss: 0.504807  [19200/40000]\n",
            "loss: 0.631315  [25600/40000]\n",
            "loss: 0.470421  [32000/40000]\n",
            "loss: 0.606053  [38400/40000]\n",
            "train loss: 0.5157989026069641, train_acc: 0.862925\n",
            "Test Error: \n",
            " Accuracy: 54.4%, Avg loss: 1.361793 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.583159  [    0/40000]\n",
            "loss: 0.452145  [ 6400/40000]\n",
            "loss: 0.364195  [12800/40000]\n",
            "loss: 0.400912  [19200/40000]\n",
            "loss: 0.638287  [25600/40000]\n",
            "loss: 0.424513  [32000/40000]\n",
            "loss: 0.485552  [38400/40000]\n",
            "train loss: 0.500823400259018, train_acc: 0.867725\n",
            "Test Error: \n",
            " Accuracy: 54.4%, Avg loss: 1.341106 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.450807  [    0/40000]\n",
            "loss: 0.446471  [ 6400/40000]\n",
            "loss: 0.336047  [12800/40000]\n",
            "loss: 0.452298  [19200/40000]\n",
            "loss: 0.523429  [25600/40000]\n",
            "loss: 0.496079  [32000/40000]\n",
            "loss: 0.349587  [38400/40000]\n",
            "train loss: 0.4925736090183258, train_acc: 0.87295\n",
            "Test Error: \n",
            " Accuracy: 54.5%, Avg loss: 1.345519 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.493485  [    0/40000]\n",
            "loss: 0.510776  [ 6400/40000]\n",
            "loss: 0.453659  [12800/40000]\n",
            "loss: 0.355059  [19200/40000]\n",
            "loss: 0.416687  [25600/40000]\n",
            "loss: 0.463485  [32000/40000]\n",
            "loss: 0.586096  [38400/40000]\n",
            "train loss: 0.48799409465789795, train_acc: 0.877125\n",
            "Test Error: \n",
            " Accuracy: 54.7%, Avg loss: 1.343036 \n",
            "\n",
            "Done!\n",
            "Best dev accuracy: 0.5471 in epoch 20\n",
            "Training time: 146.34935927391052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRGJxq13RcLv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "07d03263-4aea-4706-f755-35d6e53bb5c5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(epochs), train_losses, color='blue', label='train')\n",
        "plt.plot(range(epochs), dev_losses, color='green', label='dev')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(epochs), train_accuracies, color='blue', label='train')\n",
        "plt.plot(range(epochs), dev_accuracies, color='green', label='dev')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujhgkuaBVpbj"
      },
      "source": [
        "The development performance plateaus very early in the training process. That means that the features learned during the training phase do not help for development (new) data. Our network is learning irrelevant features for the problem. We have to attack that problem now, and our weapons are regularization techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDNKbYi5HQZ9"
      },
      "source": [
        "###Data augmentation\n",
        "Data augmentation is always a good idea and it is specially well suited for images. In Pytorch, using the torchvision library, it is remarkably easy to implement data augmentation pipelines. You can have a look [here](https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py) to see the available transformations and their effects.\n",
        "\n",
        "**EXERCISE:** Using `transforms.Compose`, build the data augmentation pipeline in the variable `our_transforms`. Use the following transforms for the pipeline: random horizontal flip (probability of 0.5), color jitter (default parameters), random crop (size $28 \\times 28$) and random invert (probability of 0.5).\n",
        "\n",
        "**NOTE FOR THE EXERCISE:** after applying a random crop, your image will become of size $28 \\times 28$. Check what you should do to restore its previous size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDtEZDiZH2cS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "outputId": "7de089c5-d753-46de-f6bc-12e23d0fa01e"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "our_transforms = transforms.Compose([\n",
        "                    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
        "                    torchvision.transforms.ColorJitter(),\n",
        "                    torchvision.transforms.RandomCrop(size=(28,28)),\n",
        "                    torchvision.transforms.RandomInvert(p=0.5),\n",
        "                    torchvision.transforms.ToTensor()])\n",
        "\n",
        "# Add the transforms to our dataset\n",
        "# NOTE: From now on, train_set will always have these transforms\n",
        "train_set.dataset.transform = our_transforms \n",
        "\n",
        "# Let's visualize some images\n",
        "train_dataloader = DataLoader(train_set, batch_size=4, shuffle=True)\n",
        "imgs, labels = next(iter(train_dataloader)) # We have a batch of 4 images and labels\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))    \n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(imgs)\n",
        "\n",
        "imshow(out, title=[labels_map[x.item()] for x in labels])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phoeGJM74K8D"
      },
      "source": [
        "Data augmentation, and all the other regularization techniques, make training more difficult, so we will need more epochs to obtain good results. However, increasing the number of epochs we also increase the training time, which is a problem for this lab. For that reason, we will restrict ourselves to 20 epochs of training and try to gain intuition looking at learning curves, and comparing regularization techniques on this basis. So, please, analyse the obtained results into this context. And be patient, since the following experiments needs around **6 minutes** to be completed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJyS_xyrSTBj"
      },
      "source": [
        "import time\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size = 64\n",
        "epochs = 20 # Restrict epochs to reduce training time\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(0)\n",
        "\n",
        "model = MyMLPBN()\n",
        "model = model.to(device)\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "dev_dataloader = DataLoader(dev_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "train_losses, train_accuracies, dev_accuracies, dev_losses  = [], [], [], []\n",
        "start = time.time()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss, train_acc = train_loop_scheduler(train_dataloader, model, loss_fn, optimizer, scheduler, device)\n",
        "    print(f'train loss: {train_loss}, train_acc: {train_acc}')\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    dev_loss, dev_acc = test_loop(dev_dataloader, model, loss_fn, device)\n",
        "    dev_losses.append(dev_loss)\n",
        "    dev_accuracies.append(dev_acc)    \n",
        "end = time.time()\n",
        "print(\"Done!\")\n",
        "\n",
        "print(f'Best dev accuracy: {max(dev_accuracies)} in epoch {dev_accuracies.index(max(dev_accuracies))+1}')\n",
        "print(f'Training time: {end-start}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HusEPygXdBrv"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(epochs), train_losses, color='blue', label='train')\n",
        "plt.plot(range(epochs), dev_losses, color='green', label='dev')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(epochs), train_accuracies, color='blue', label='train')\n",
        "plt.plot(range(epochs), dev_accuracies, color='green', label='dev')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFlA2kGSu_d5"
      },
      "source": [
        "Learning curves are completely different now. Training and dev metrics are going together, which means that training performance is transferring to development performance. However, as can be seen, the best training accuracy (\\~0.50) is very far from the accuracies we obtained without data augmentation (\\~0.98). That means that training is now much harder, as the model is processing different images in each epoch. But our objective is to improve the performance in new images, i.e. dev accuracy. The best dev accuracy is 0.50, close to what we obtained with the previous model. Take into account that we trained only for 20 epochs now. And if we look at the curves, it seems our model could keep improving. Also you can try different transformations, besides the ones used here, and see what combination works better for this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsp8HEa3HPPp"
      },
      "source": [
        "###Weight decay\n",
        "Another regularization technique we saw is **weight decay**. More concretely, we will use $L2$ regularization, specifying a value for the hyperparameter $\\lambda$. \n",
        "\n",
        "**EXERCISE:** Modify the code below to include weight decay in our training process (expected training time around **6 minutes**). \n",
        "\n",
        "**HINT:** In Pytorch, weight decay has to be added in the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-C8u3TyV93P"
      },
      "source": [
        "import time\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "weight_decay = 1e-3\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(0)\n",
        "\n",
        "model = MyMLPBN()\n",
        "model = model.to(device)\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "dev_dataloader = DataLoader(dev_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "### WRITE YOUR CODE HERE ### (≈ 1 line)\n",
        "\n",
        "########################\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "train_losses, train_accuracies, dev_accuracies, dev_losses  = [], [], [], []\n",
        "start = time.time()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss, train_acc = train_loop_scheduler(train_dataloader, model, loss_fn, optimizer, scheduler, device)\n",
        "    print(f'train loss: {train_loss}, train_acc: {train_acc}')\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    dev_loss, dev_acc = test_loop(dev_dataloader, model, loss_fn, device)\n",
        "    dev_losses.append(dev_loss)\n",
        "    dev_accuracies.append(dev_acc)    \n",
        "end = time.time()\n",
        "print(\"Done!\")\n",
        "\n",
        "print(f'Best dev accuracy: {max(dev_accuracies)} in epoch {dev_accuracies.index(max(dev_accuracies))+1}')\n",
        "print(f'Training time: {end-start}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPWPgXgy6gcO"
      },
      "source": [
        "Using only data augmentation, we obtained 0.5 best dev accuracy. Now, we get 0.504, which is a slight improvement. Different values for $\\lambda$ should be tested, using random search, for example. However, I would not expect big improvements with weight decay in this specific problem. In any case, let's see the learning curves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ_gw3suaZZC"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(epochs), train_losses, color='blue', label='train')\n",
        "plt.plot(range(epochs), dev_losses, color='green', label='dev')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(epochs), train_accuracies, color='blue', label='train')\n",
        "plt.plot(range(epochs), dev_accuracies, color='green', label='dev')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1cc9S8glouA"
      },
      "source": [
        "Again, we can see that train and dev metrics are going together, which is  good."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qtTymXcpRcK"
      },
      "source": [
        "###Dropout\n",
        "We will try to use dropout. There are still some [discussions](https://stackoverflow.com/questions/39691902/ordering-of-batch-normalization-and-dropout) regarding batch normalization and dropout. It is not clear whether they should be used together and how. Here, we will try to combine both techniques and see how it performs.\n",
        "\n",
        "**EXERCISE:** Implement the `forward` dunction of the new class `MyMLPBNDrop` combining the usage of batch normalization and dropout. We added `dropout` as argument in the function `__init__` to specify the dropout probability. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iNIXzzfpnpp"
      },
      "source": [
        "class MyMLPBNDrop(nn.Module):\n",
        "    def __init__(self, dropout):\n",
        "      super(MyMLPBNDrop, self).__init__()\n",
        "      self.p = dropout\n",
        "      self.flatten = nn.Flatten()\n",
        "      self.linear1 = nn.Linear(3*32*32, 512)\n",
        "      torch.nn.init.kaiming_uniform_(self.linear1.weight)\n",
        "      self.bn1 = nn.BatchNorm1d(num_features=512)\n",
        "      self.linear2 = nn.Linear(512, 512)\n",
        "      torch.nn.init.kaiming_uniform_(self.linear2.weight)\n",
        "      self.bn2 = nn.BatchNorm1d(num_features=512)\n",
        "      self.linear3 = nn.Linear(512, 10)\n",
        "      torch.nn.init.kaiming_uniform_(self.linear3.weight)      \n",
        "\n",
        "    def forward(self, x):\n",
        "      ### WRITE YOUR CODE HERE ### (≈ 10 lines)\n",
        "      \n",
        "      \n",
        "      ########################\n",
        "      return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HroHRZ1p79ep"
      },
      "source": [
        "We will train the new model with dropout to see its performance. The expected training time for the next experiment is around **12 minutes**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPgPmxF_8Ldp"
      },
      "source": [
        "import time\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "weight_decay = 1e-3\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(0)\n",
        "\n",
        "model = MyMLPBNDrop(0.5) # We will use 0.5 probability to drop neurons out\n",
        "model = model.to(device)\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "dev_dataloader = DataLoader(dev_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "train_losses, train_accuracies, dev_accuracies, dev_losses  = [], [], [], []\n",
        "start = time.time()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss, train_acc = train_loop_scheduler(train_dataloader, model, loss_fn, optimizer, scheduler, device)\n",
        "    print(f'train loss: {train_loss}, train_acc: {train_acc}')\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    dev_loss, dev_acc = test_loop(dev_dataloader, model, loss_fn, device)\n",
        "    dev_losses.append(dev_loss)\n",
        "    dev_accuracies.append(dev_acc)    \n",
        "end = time.time()\n",
        "print(\"Done!\")\n",
        "\n",
        "print(f'Best dev accuracy: {max(dev_accuracies)} in epoch {dev_accuracies.index(max(dev_accuracies))+1}')\n",
        "print(f'Training time: {end-start}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t90PyHqrAE_w"
      },
      "source": [
        "Both train and dev accuracy are lower than before. More concretely, best dev accuracy is now 0.38, far from the 0.5 we got before. Again, my guess is that we should train much longer to see the effects of dropout better. We should also test different dropout rates and combination approaches with batch normalization. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0859IvbsFWeb"
      },
      "source": [
        "##Performance on test data\n",
        "Even though our exploration has not been exhaustive, we obtained very interesting conclusions for this specific task:\n",
        "\n",
        "1.   One time setup considerations:\n",
        "\n",
        "\n",
        "*   Data prepocessing: scaled data (values between $[0, 1]$) works well.\n",
        "*   Weight initialization: He intialization is the best option.\n",
        "*   Batch normalization: use it!\n",
        "\n",
        "2.   Improve your training error.\n",
        "\n",
        "\n",
        "*   Optimizers: Adam with $\\alpha=10^{-4}$ works.\n",
        "*   Schedulers: using cosine scheduler we improve training results slightly.\n",
        "\n",
        "\n",
        "3.   Improve your test error.\n",
        "\n",
        "\n",
        "*   Data augmentation helps considerably.\n",
        "*   Weight decay offers slight improvements.\n",
        "*   Dropout does not help for this problem, although we haven't explored it enough."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BIAh98DK4dF"
      },
      "source": [
        "Let's train our final model, combining all those lessons and using **Early Stopping** for model selection. For Early Stopping, we have to make some decisions:\n",
        "\n",
        "\n",
        "1.   What performance indicator are we going to use to stop? In principle, we can choose between training loss, training accuracy, dev loss and dev accuracy. As we are trying to maximize dev accuracy, that will be our target metric.\n",
        "2.   How many epochs of patience will we allow? Patience is very important. Early stopping halts the training process when we do not improve a certain metric (dev accuracy, for example). However, patience allows to wait for some epochs before stopping. It could be the case where we do not improve for 4 epochs, but in the fifth one, we obtain a better result. If our patience is 0, we will not allow that kind of behaviours. So it is convenient to set a positive patience value, which is usually dependent on the total number of epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvYoOCm_Nadn"
      },
      "source": [
        "As this is the final training process, you can set a big number of epochs. Early stopping will halt the process if no improvements are observed!\n",
        "\n",
        "**EXERCISE:** Implement Early Stopping with patience. Basically, you have to implement an if-else statement. If current `dev_acc` is greater than the best value so far, store it and save the model to disk under the name of *model.pth*. Else, update the variable `epoch_no_improve` and if it is equal than `patience`, halt the process. \n",
        "\n",
        "**WARNING!** Long training process ahead! The following training process takes more than 40 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbAvi8oII3ch"
      },
      "source": [
        "import time\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size = 64\n",
        "epochs = 150\n",
        "weight_decay = 1e-3\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(0)\n",
        "\n",
        "model = MyMLPBN()\n",
        "model = model.to(device)\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "dev_dataloader = DataLoader(dev_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "# Early stopping stuff\n",
        "patience = 10\n",
        "best_dev_acc = 0.0\n",
        "epochs_no_improve = 0\n",
        "\n",
        "train_losses, train_accuracies, dev_accuracies, dev_losses  = [], [], [], []\n",
        "start = time.time()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss, train_acc = train_loop_scheduler(train_dataloader, model, loss_fn, optimizer, scheduler, device)\n",
        "    print(f'train loss: {train_loss}, train_acc: {train_acc}')\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    dev_loss, dev_acc = test_loop(dev_dataloader, model, loss_fn, device)\n",
        "    dev_losses.append(dev_loss)\n",
        "    dev_accuracies.append(dev_acc)\n",
        "\n",
        "    # Early stopping code\n",
        "    ### WRITE YOUR CODE HERE ### (≈ 9 lines)\n",
        "    \n",
        "    ########################\n",
        "\n",
        "end = time.time()\n",
        "print(\"Done!\")\n",
        "\n",
        "print(f'Best dev accuracy: {max(dev_accuracies)} in epoch {dev_accuracies.index(max(dev_accuracies))+1}')\n",
        "print(f'Training time: {end-start}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDGXPzIZA2dr"
      },
      "source": [
        "In my case, the experiment stopped at epoch 102. The best dev accuracy is 0.5763, obtained at epoch 92 (totally expected, as the patience value is 10). \n",
        "\n",
        "**HINT:** if you go to the file explorer in the left hand side of Colab, you can see the stored model *model.pth*. As Colab sessions are volatile, download the model to your local disk just in case. You can upload any file to your Colab disk in any moment.\n",
        "\n",
        "Let's visualize the learning curves:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31CgLMRVKaV5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(len(train_losses)), train_losses, color='blue', label='train')\n",
        "plt.plot(range(len(train_losses)), dev_losses, color='green', label='dev')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(len(train_accuracies)), train_accuracies, color='blue', label='train')\n",
        "plt.plot(range(len(train_accuracies)), dev_accuracies, color='green', label='dev')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SomtpPj1Bm9p"
      },
      "source": [
        "As said before, using regularization makes training more difficult, so the network needs more epochs. We can observe that training and development metrics are going together, but the gap between both is getting bigger and bigger as epochs increase. In the final epochs, training continues its slow improvement. However, development no longer improves. Although we use regularization techniques, we cannot prevent overfitting completely. In any case, remember that our first unregularized model had 0.54 dev accuracy. The regularized one is above 0.57, so the improvement is significant. Probably, using a higher patience value, we could even improve a little bit more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrXNLl16P_WW"
      },
      "source": [
        "Now comes the most important part. Let's load the best model from our training process, stored in the disk and check its performance on test data. Test images have not been used during the design and development stages of our neural network, so they are acutally **new data**. The performance estimation obtained using those images will be a very good estimation of the real performance of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb3ylwnVQB5J"
      },
      "source": [
        "model = torch.load('model.pth', map_location=torch.device(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvlwgU9EQC0B"
      },
      "source": [
        "Finally, download the test set and see how our model performs!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzsyqXzAG7Xp"
      },
      "source": [
        "test_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n",
        "\n",
        "print(f'Number of images: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nMSXbfuQMUC"
      },
      "source": [
        "batch_size = 64\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "test_loss, test_acc = test_loop(test_dataloader, model, loss_fn, device)\n",
        "\n",
        "print(f'test loss: {test_loss}, test accuracy: {test_acc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7at3tli0QXLB"
      },
      "source": [
        "**This is our final result: 0.5837**. Our model can correctly classify almost 6 out of 10 images. Is this good enough? It depends on the application we pursue. But to have an idea, why don't you try it yourself?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rWYvhLhJS4v"
      },
      "source": [
        "# Let's visualize some images\n",
        "test_dataloader = DataLoader(test_data, batch_size=10, shuffle=True)\n",
        "imgs, labels = next(iter(test_dataloader)) # We have a batch of 10 images and labels\n",
        "\n",
        "# Make the predictions with our network\n",
        "model.eval()\n",
        "preds = model(imgs.to(device))\n",
        "pred_indices = preds.argmax(1).to('cpu').numpy()\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))    \n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(imgs, nrow=10) # TODO: test this\n",
        "\n",
        "#imshow(out, title=[labels_map[x.item()] for x in labels])\n",
        "imshow(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29xvgZfWdd7j"
      },
      "source": [
        "Make your guess! You can right click the image above and open it in a new tab to zoom in and see each image better. Remember the possible labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhHcs-ecdobf"
      },
      "source": [
        "labels_map "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnZuCijpdvj4"
      },
      "source": [
        "Here you have the predictions of the network and the real labels. What about you? Are you better than our network?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_OpVpWgd182"
      },
      "source": [
        "pred_labels = [labels_map[x] for x in pred_indices]\n",
        "print(f'Predicted labels: {pred_labels}')\n",
        "gt_labels = [labels_map[x.item()] for x in labels]\n",
        "print(f'Real labels: {gt_labels}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UubGFQRFQdFw"
      },
      "source": [
        "**FINAL NOTES:**\n",
        "\n",
        "In this lab, we have seen that the techniques to improve the training performance work very well. Weight initialization, batch normalization, optimizers and schedulers helped us to reach 0.98 training accuracy with a neural network that initially was only able to reach 0.29. \n",
        "\n",
        "However, when we tried to improve our test performance, we were not *that* successful. The first model we tested in development data had an accuracy of 0.54. After exploring data augmentation, weight decay and dropout, we managed to achieve an accuracy above 0.57. Compared to how training evolved, testing improvement might seem quite poor. But there are several reasons for this:\n",
        "\n",
        "\n",
        "1.   Given the limited time of the labs and the relatively long training times required, we could not explore in depth all the regularization alternatives. More experiments regarding different transformations for data augmentation, weight decay values and dropout values and configurations could be run. Surely, we could improve even more our final performance.\n",
        "2.   Regularization is much more difficult than optimization. The real challenge in machine learning in general, and deep learning in particular, is **generalization**. Nowadays, optimization is better understood and stronger solutions have been proposed.\n",
        "3.   In this lab, we did not explore different neural network architectures. It is well known that MLPs overfit easily to high-dimensional input data, such as images. Even though we try much harder, we will always have the limits imposed by the real capacity of our MLP. Indeed, for images (and for other input types also) a different neural architecture is more suitable: **Convolutional Neural Networks**. And that is precisely the next topic of our course!\n",
        "\n"
      ]
    }
  ]
}